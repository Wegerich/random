{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data sources are:\n",
    "\n",
    "### 1. Liam's SPSS coded data\n",
    "**File:** The Loop 2017 Final Interventions.xlsx\n",
    "\n",
    "Exported as Excel from SPSS, keeping the variable names.\n",
    "\n",
    "This file contains 1325 entries.\n",
    "\n",
    "\n",
    "27 have null festival or sample numbers so can't be used, leaving 1298\n",
    "\n",
    "\n",
    "One has sample number 12151, two have sample number 0 - these cannot be merged.\n",
    "\n",
    "\n",
    "This leaves 1295 - all of which can be merged\n",
    "\n",
    "### 2. Guy's cleaned up lab data\n",
    "**File:** Loop 2017 Lab fixed data.csv\n",
    "\n",
    "Saved from: Dropbox/Testing/2017 results processing/Loop 2017 Lab fixed data.xlsm in the ‘Raw Lab Data’ sheet\n",
    "\n",
    "This file contains 2544 entries\n",
    "\n",
    "\n",
    "1900 entries start with F\n",
    "\n",
    "\n",
    "621 entries begin with A (amnesty) so can't be merged\n",
    "\n",
    "\n",
    "23 Begin with W? so can't be merged\n",
    "\n",
    "\n",
    "Entry SGP2017 F0465 needs editing as 'Client gender' is FemaleaMalee \n",
    "\n",
    "### 3. Boomtown Intervention Questionnaire\n",
    "**File:** BTReport 2017 - Form responses 3.csv\n",
    "\n",
    "Exported from: https://docs.google.com/spreadsheets/d/15pdETY0HK-VbBcV-N0swt6ZrRBbeDnZR5RGDzfq95dg\n",
    "\n",
    "This file contains 194 entries\n",
    "\n",
    "### Merging the data\n",
    "\n",
    "Merging the data on Festival and SampleNumber resulted in 1295 entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298\n"
     ]
    }
   ],
   "source": [
    "spssdata = '/opt/random/The Loop 2017 Final Interventions.xlsx'\n",
    "\n",
    "spss_df = pd.read_excel(spssdata)\n",
    "\n",
    "# Change festival names\n",
    "spss_df['Festival'].replace(['BoomTown', 'KC', 'SGP'], ['BT2017', 'KC2017', 'SGP2017'], inplace=True)\n",
    "\n",
    "# Ensure all Sample numbers are consistent\n",
    "# 1. Delete any rows where SampleNumber or Festival is NA as we can't do anything with it\n",
    "spss_df.dropna(subset=['SampleNumber', 'Festival'], inplace=True)\n",
    "\n",
    "# 2. Make all sample numbers a 4-digit code starting with F\n",
    "spss_df['SampleNumber'] = spss_df['SampleNumber'].apply(lambda x: 'F{:04d}'.format(int(x)))\n",
    "\n",
    "# Combine date and time columns into new single column\n",
    "spss_df['Date'] = pd.to_datetime(spss_df['Date']) # Convert Date to datetime object\n",
    "spss_df['Date & Time of intervention'] = spss_df.apply(lambda r : pd.datetime.combine(r['Date'], r['Time']), 1)\n",
    "\n",
    "# Remove Day, Date, Time and SurveyID columns\n",
    "spss_df.drop(['Day', 'Date', 'Time', 'SurveyID'], axis=1, inplace=True)\n",
    "\n",
    "# Below shows we are left with 1298 datasets\n",
    "print(len(spss_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labdata = '/opt/random/Loop 2017 Lab fixed data.csv'\n",
    "date_cols = ['Sample submission time', 'Date & Time of return']\n",
    "lab_df = pd.read_csv(labdata, encoding=\"ISO-8859-1\", engine=\"python\", parse_dates=date_cols)\n",
    "\n",
    "# Remame 'Event Name' and 'Sample Number' columns so they match\n",
    "lab_df.rename(columns={'Event  Name': 'Festival', 'Sample Number': 'SampleNumber'}, inplace=True)\n",
    "\n",
    "# Delete any rows where SampleNumber or Festival is NA as we can't do anything with it\n",
    "lab_df.dropna(subset=['SampleNumber', 'Festival'], inplace=True) # This just drops one case\n",
    "\n",
    "# Uppercase all sample numbers\n",
    "labels = ['SampleNumber']\n",
    "lab_df.loc[:, labels] = lab_df[labels].apply(lambda x: x.str.upper())\n",
    "\n",
    "# Some sample numbers begin with W or F \n",
    "#print(len(lab_df[ ~ (lab_df['SampleNumber'].str.startswith('F') | lab_df['SampleNumber'].str.startswith('A')) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295 entries were merged\n"
     ]
    }
   ],
   "source": [
    "dft = pd.merge(spss_df, lab_df, how='inner', on=['Festival','SampleNumber'])\n",
    "print(\"%d entries were merged\" % len(dft))\n",
    "\n",
    "# For checking which entries can't be merged - check for right_only\n",
    "#pd.merge(lab_df, spss_df, how='outer', indicator=True)\n",
    "\n",
    "# Sort first by Festival, then SampleNumber\n",
    "dft.sort_values(['Festival', 'SampleNumber'], ascending=True, inplace=True)\n",
    "\n",
    "# Here we reorder columns that should be identical to:\n",
    "# 1. spot data errors\n",
    "# 2. remove duplicate columns once we're happy data is consistent\n",
    "prefix_cols = ['Festival', 'SampleNumber',\n",
    "             'Sample submission time', 'Date & Time of return', 'Date & Time of intervention', \n",
    "             'Client age', 'Age', 'Client gender', 'Gender', 'Bought as', 'SubmittedSubstanceAs']\n",
    "\n",
    "# Get the list of columns excluding the ones in prefix_cols\n",
    "cols = [c for c in dft.columns.tolist() if c not in prefix_cols]\n",
    "# Prepend prefix_cols to create the new list\n",
    "cols = prefix_cols + cols\n",
    "# Reorder columns\n",
    "dft = dft[cols]\n",
    "\n",
    "# Uppercase all genders for consistency\n",
    "labels = ['Client gender', 'Gender']\n",
    "dft.loc[:, labels] = dft[labels].apply(lambda x: x.str.upper())\n",
    "# Set any MISSING to be nan\n",
    "dft.loc[:, labels] = dft.loc[:, labels].replace({'MISSING':np.nan})\n",
    "\n",
    "# Dump to excel\n",
    "writer = pd.ExcelWriter('merged.xlsx')\n",
    "dft.to_excel(writer, 'MergedData', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # See which non-na ages don't match\n",
    "# # 540 entries have valid ages\n",
    "# print(len(dft))\n",
    "# df = dft[pd.notnull(dft['Client age']) & pd.notnull(dft['Age'])]\n",
    "# print(len(df))\n",
    "# df = df[df['Client age'] != df['Age']]\n",
    "# # 127 don't match\n",
    "# print(len(df))\n",
    "# # df.to_csv('foo.csv')\n",
    "\n",
    "\n",
    "# Cross tab 'Client gender' and 'Gender\n",
    "#print(dft['Client gender'].unique())\n",
    "#print(dft['Gender'].unique())\n",
    "\n",
    "# # Look where they don't match\n",
    "# df = dft[pd.notnull(dft['Client gender']) & pd.notnull(dft['Gender'])]\n",
    "# df = df[df['Client gender'] != df['Gender']]\n",
    "# # 127 don't match\n",
    "# print(len(df))\n",
    "# df.to_csv('foo.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ever month today today_tonight tonight week year yesterday\n",
      "0     No    No    No            No      No   No   No        No\n",
      "1    Yes   Yes    No            No      No  Yes  Yes       Yes\n",
      "2     No    No    No            No      No   No   No        No\n",
      "3    Yes   Yes   Yes           Yes      No  Yes  Yes       Yes\n",
      "4    Yes    No    No            No      No   No  Yes        No\n",
      "5    Yes   Yes    No            No      No   No  Yes        No\n",
      "6    Yes    No    No            No      No   No   No        No\n",
      "7    Yes   Yes    No            No      No   No  Yes        No\n",
      "8    Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "9    Yes   Yes   Yes           Yes      No  Yes  Yes       Yes\n",
      "10   Yes   Yes    No            No      No   No  Yes        No\n",
      "11   Yes   Yes   Yes           Yes      No  Yes  Yes       Yes\n",
      "12   Yes   Yes    No            No      No  Yes  Yes        No\n",
      "13   Yes   Yes   Yes           Yes      No  Yes  Yes       Yes\n",
      "14   Yes    No    No            No      No   No  Yes        No\n",
      "15   Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "16   Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "17   Yes    No    No            No      No   No  Yes        No\n",
      "18   Yes   Yes    No            No      No  Yes  Yes        No\n",
      "19   Yes    No    No            No      No   No  Yes        No\n",
      "20   Yes   Yes    No            No      No  Yes  Yes        No\n",
      "21   Yes    No    No            No      No   No  Yes        No\n",
      "22   Yes   Yes    No            No      No   No  Yes        No\n",
      "23    No    No    No            No      No   No   No        No\n",
      "24   Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "25   Yes    No    No            No      No   No  Yes        No\n",
      "26   Yes    No    No            No      No   No  Yes        No\n",
      "27   Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "28   Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "29   Yes   Yes   Yes           Yes      No  Yes  Yes       Yes\n",
      "..   ...   ...   ...           ...     ...  ...  ...       ...\n",
      "163  Yes    No    No            No      No   No  Yes        No\n",
      "164   No    No    No            No      No   No   No        No\n",
      "165   No    No    No            No      No   No   No        No\n",
      "166   No    No    No            No      No   No   No        No\n",
      "167  Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "168   No    No    No            No      No   No   No        No\n",
      "169  Yes    No    No            No      No   No  Yes        No\n",
      "170  Yes   Yes    No            No      No   No  Yes        No\n",
      "171   No    No    No            No      No   No   No        No\n",
      "172  Yes   Yes    No            No      No  Yes  Yes        No\n",
      "173  Yes    No    No            No      No   No   No        No\n",
      "174  Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "175   No    No    No            No      No   No   No        No\n",
      "176   No    No    No            No      No   No   No        No\n",
      "177  Yes    No    No            No      No   No   No        No\n",
      "178  Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "179  Yes    No    No            No      No   No  Yes        No\n",
      "180  Yes   Yes    No            No      No  Yes  Yes       Yes\n",
      "181  Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "182   No    No    No            No      No   No   No        No\n",
      "183   No    No    No            No      No   No   No        No\n",
      "184   No    No    No            No      No   No   No        No\n",
      "185  Yes   Yes    No            No      No  Yes  Yes       Yes\n",
      "186  Yes    No    No            No      No   No  Yes        No\n",
      "187  Yes    No    No            No      No   No  Yes        No\n",
      "188  Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "189   No    No    No            No      No   No   No        No\n",
      "190  Yes    No    No            No      No   No  Yes        No\n",
      "191  Yes   Yes    No            No      No   No  Yes        No\n",
      "192  Yes   Yes   Yes           Yes     Yes  Yes  Yes       Yes\n",
      "\n",
      "[193 rows x 8 columns]\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Attempt to disentangle the Form responses into a form they can be merged with Liam's data\n",
    "#\n",
    "bt_interventions = '/opt/random/BTReport 2017 - Form responses 3.csv'\n",
    "date_cols = ['Timestamp']\n",
    "bt_df = pd.read_csv(bt_interventions, engine=\"python\", parse_dates=date_cols)\n",
    "\n",
    "\"\"\"\n",
    "Which drugs have you used? [Cocaine]\n",
    "\n",
    "cocaine_ever\tEver had this drug \n",
    "cocaine_year\tEver had this drug in the past year\n",
    "cocaine_month\tEver had this drug in the past month\n",
    "cocaine_week\tEver had this drug in the past week\n",
    "cocaine_yesterday\tEver had this drug yesterday\n",
    "cocaine_today\tEver had this drug today\n",
    "cocaine_tonight\tAre you having this drug tonight\n",
    "cocaine_today_tonight\tHave they had this drug today or will they have it tonight?\n",
    "\n",
    "Take column -> return df with names matching Liam's coding\n",
    "\n",
    "For each cell -> split by commas to get all values\n",
    "Return boolean of which columns apply\n",
    "\n",
    "'ever', \n",
    "'year',\n",
    "'month',\n",
    "'week',\n",
    "'yesterday',\n",
    "'today',\n",
    "'tonight',\n",
    "'today_tonight',\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "c = 'Never had, Had today, (Probably) planning later'\n",
    "#c = 'Had in last month, Had in last year'\n",
    "def parse_cell(cell):\n",
    "    \"\"\"Parse response of drug questionaire, returning Yes/No for:\n",
    "    ['ever', 'year', 'month', 'week', 'yesterday', 'today', 'tonight', 'today_tonight']\n",
    "    \"\"\"\n",
    "    form_responses = ['(Probably) planning later', 'Had today', 'Had yesterday', 'Had in last week', 'Had in last month', 'Had in last year', 'Had in my life']\n",
    "    len_responses = len(form_responses) \n",
    "    if isinstance(cell, float) and np.isnan(cell): # If Nan assume all No's\n",
    "        return ['No'] * (len_responses + 1) # Need to add one as result has today_tonight value\n",
    "    \n",
    "    #form_responses = ['Had in my life', 'Had in last year', 'Had in last month', 'Had in last week', 'Had yesterday', 'Had today', '(Probably) planning later']\n",
    "    values = [v.strip() for v in cell.split(',')]\n",
    "    flags = [True] * len_responses\n",
    "    # As everything is set true we set false for any we don't see and break as soon as we encounter a value\n",
    "    for i, response in enumerate(form_responses):\n",
    "        if response in values:\n",
    "            break\n",
    "        flags[i] = False\n",
    "    \n",
    "    # Add 'today_tonight'\n",
    "    today = 0\n",
    "    tonight = 1\n",
    "    today_tonight = False\n",
    "    if flags[today] or flags[tonight]:\n",
    "        today_tonight = True\n",
    "    flags = [today_tonight] + flags\n",
    "    \n",
    "    # Reverse list as columns are in opposite order\n",
    "    flags.reverse()\n",
    "    return list(map(lambda x: 'Yes' if x else 'No', flags))\n",
    "\n",
    "#print(parse_cell(np.nan))\n",
    "\n",
    "# clabel = 'Which drugs have you used? [Cocaine]'\n",
    "# df = pd.DataFrame(bt_df[clabel])\n",
    "# #print(parse_cell(df[clabel]))\n",
    "# #print(df[clabel].apply(parse_cell))\n",
    "# #df['ever', 'year', 'month', 'week', 'yesterday', 'today', 'tonight', 'today_tonight'] = zip(*df[clabel].apply(parse_cell))\n",
    "\n",
    "# #df['ever'], df['year'], df['month'], df['week'], df['yesterday'], df['today'], df['tonight'], df['today_tonight'] = zip(*df[clabel].apply(parse_cell))\n",
    "\n",
    "#x = df[clabel].apply(parse_cell)\n",
    "#print(x)\n",
    "# y = list(zip(x))\n",
    "\n",
    "# pd.DataFrame(q_list, columns=['q_data']) \n",
    "\n",
    "\n",
    "#x = pd.DataFrame(zip(*df[clabel].apply(parse_cell)))\n",
    "#print(x)\n",
    "keys = ['ever', 'year', 'month', 'week', 'yesterday', 'today', 'tonight', 'today_tonight']\n",
    "values = list(zip(*df[clabel].apply(parse_cell)))\n",
    "d = dict(zip(keys, values))\n",
    "\n",
    "\n",
    "x = pd.DataFrame(d)\n",
    "print(x)\n",
    "# df.assign(**d)\n",
    "\n",
    "#df[['ever', 'year', 'month','week','yesterday','today','tonight','today_tonight']] = zip(*df[clabel].apply(parse_cell))\n",
    "\n",
    "\n",
    "#df.to_csv('foo.csv')\n",
    "print(\"DONE\")\n",
    "# clabel = 'Which drugs have you used? [Cocaine]'\n",
    "# print(bt_df[clabel].unique())\n",
    "\n",
    "# df = pd.DataFrame(bt_df[clabel])\n",
    "# #print(df)\n",
    "# #df.pivot(index='date', columns='variable', values='value')\n",
    "# df = df.pivot(columns=clabel, values=clabel)\n",
    "\n",
    "# # Remove any nan columns and the label we've used\n",
    "# df.drop(np.nan, axis=1, inplace=True)\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
