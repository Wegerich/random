{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues with MADE dataset:\n",
    "FTIR\n",
    "* Dodgy sample numbers\n",
    "* 2 Hit confidence columns\n",
    "* 2 substance detected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fix_sample_number(x):\n",
    "    \"\"\"Make sure all samples numbers are of form: AXXX (where A is one of A, F, W and X is a digit)\"\"\"\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return x # leave NaN's alone\n",
    "    if (isinstance(x, str) or isinstance(x, unicode)) and len(x) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        sn = 'F{:04d}'.format(int(x))\n",
    "    except ValueError:\n",
    "        # Assume string so make sure it's of the right format\n",
    "        sn = str(x).strip().capitalize()\n",
    "    if sn[0] not in ['A', 'F', 'W'] or len(sn) != 5:\n",
    "        print(\"!!! Bad ID \\'%s\\'\" % sn)\n",
    "    return sn\n",
    "\n",
    "def now():\n",
    "    return datetime.datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "\n",
    "def enumerate_duplicates(row):\n",
    "    \"\"\"Append a counter to duplicate labels\"\"\"\n",
    "    SEPARATOR = '.'\n",
    "    duplicates = {}\n",
    "    updated_row = []\n",
    "    for r in row:\n",
    "        count = duplicates.get(r, 0)\n",
    "        if count > 0:\n",
    "            label = \"{}{}{}\".format(r, SEPARATOR, count)\n",
    "        else:\n",
    "            label = r\n",
    "        updated_row.append(label)\n",
    "        duplicates[r] = count + 1\n",
    "    return updated_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ftir_csv = 'MADE/FTIR Analysis Data Recording Form.csv'\n",
    "catalog_csv = 'MADE/Sample Cataloguing Form.csv'\n",
    "reagent_csv = 'MADE/Reagent Outcomes.csv'\n",
    "hr_csv = 'MADE/MADE MAST Intervention Questionnaire.csv'\n",
    "\n",
    "date_cols = ['Timestamp']\n",
    "df_ftir = pd.read_csv(ftir_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_catalog = pd.read_csv(catalog_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_reagent = pd.read_csv(reagent_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_hr = pd.read_csv(hr_csv, engine=\"python\", parse_dates=date_cols)\n",
    "\n",
    "mla_excel = 'MADE/MADE - Loop 2018 event results sheet_.xlsx'\n",
    "df_mla = pd.read_excel(mla_excel, sheetname='MLA', header=1)\n",
    "\n",
    "# Sort out column names\n",
    "df_reagent.rename(columns={'Sample Code':'Sample Number', 'Substance(s) detected' : 'Reagent Result'}, inplace=True)\n",
    "df_hr.rename(columns={'Sample Number:':'Sample Number'}, inplace=True)\n",
    "df_mla.rename(columns={'Sample Num':'Sample Number'}, inplace=True)\n",
    "\n",
    "# Make all sample numbers a 4-digit code starting with F\n",
    "df_ftir['Sample Number'] = df_ftir['Sample Number'].apply(fix_sample_number)\n",
    "df_catalog['Sample Number'] = df_catalog['Sample Number'].apply(fix_sample_number)\n",
    "df_reagent['Sample Number'] = df_reagent['Sample Number'].apply(fix_sample_number)\n",
    "df_hr['Sample Number'] = df_hr['Sample Number'].apply(fix_sample_number)\n",
    "df_mla['Sample Number'] = df_mla['Sample Number'].apply(fix_sample_number)\n",
    "\n",
    "# Prune down MLA to valid sample numbers\n",
    "df_mla = df_mla[df_mla['Sample Number'].notnull()]\n",
    "\n",
    "DataFrames = namedtuple('DataFrames', ['catalog', 'ftir', 'reagent','mla', 'hr'])\n",
    "dfs = DataFrames(\n",
    "    catalog=df_catalog,\n",
    "    ftir=df_ftir,\n",
    "    reagent=df_reagent,\n",
    "    mla=df_mla,\n",
    "    hr=df_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING BOOMTOWN\n",
      "Canonicalising catalog\n",
      "!!! Bad ID 'R0876'\n",
      "Canonicalising ftir\n",
      "!!! Bad ID 'F00129'\n",
      "!!! Bad ID 'Z1000'\n",
      "!!! Bad ID 'B0076'\n",
      "Canonicalising reagent\n",
      "!!! Bad ID 'Z1000'\n",
      "!!! Bad ID 'Yellow > green'\n",
      "!!! Bad ID 'F1819 (or 1827?)'\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "!!! Bad ID 'G0037'\n",
      "!!! Bad ID 'G0242'\n",
      "!!! Bad ID 'G0153'\n",
      "!!! Bad ID 'G0024'\n",
      "!!! Bad ID 'G0652'\n",
      "!!! Bad ID 'G9999'\n",
      "!!! Bad ID 'G0877'\n",
      "!!! Bad ID 'G0878'\n",
      "!!! Bad ID 'G0811'\n",
      "!!! Bad ID 'G1441'\n",
      "!!! Bad ID 'G1216'\n",
      "!!! Bad ID 'G1228'\n",
      "!!! Bad ID 'G1229'\n",
      "!!! Bad ID 'G1398'\n",
      "!!! Bad ID 'G1284'\n",
      "!!! Bad ID 'G1572'\n",
      "!!! Bad ID 'G0875'\n",
      "!!! Bad ID 'G1833'\n",
      "!!! Bad ID 'G1703'\n",
      "!!! Bad ID 'G1860'\n",
      "!!! Bad ID 'G1859'\n",
      "!!! Bad ID 'G1699'\n",
      "!!! Bad ID 'G1686'\n",
      "!!! Bad ID 'G1312'\n",
      "!!! Bad ID 'G0420'\n",
      "!!! Bad ID 'G0983'\n",
      "!!! Bad ID 'G0981'\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = 'raise'\n",
    "\n",
    "# Need to define in main or we can't pickle the data objects\n",
    "class DataFrames(object):\n",
    "    def __init__(self):\n",
    "        catalog = None\n",
    "        ftir = None\n",
    "        reagent = None\n",
    "        mla = None\n",
    "        hr = None\n",
    "\n",
    "def gsheets_service():\n",
    "    from googleapiclient.discovery import build\n",
    "    from httplib2 import Http\n",
    "    from oauth2client import file, client, tools\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    CREDS_FILE = '/opt/random/MADE/JensDataExportJupyter_client_secret.json'\n",
    "    SCOPES = 'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        import argparse\n",
    "        flags = argparse.ArgumentParser(parents=[tools.argparser]).parse_args([])\n",
    "        flow = client.flow_from_clientsecrets(CREDS_FILE, SCOPES)\n",
    "        creds = tools.run_flow(flow, store, flags)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "    return service\n",
    "\n",
    "def get_df(service, SPREADSHEET_ID, SS_RANGE, mla=False):\n",
    "    # Call the Sheets API\n",
    "    result = service.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                                range=SS_RANGE).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('*** No data found ***')\n",
    "        return None\n",
    "\n",
    "    # mla has irrelevant stuff in columns 1 and 3 and sample numbers in first column\n",
    "    if mla:\n",
    "        values.pop(0)\n",
    "        values.pop(1)\n",
    "        def not_blank(row):\n",
    "            return len(row[0]) > 0       \n",
    "    else:\n",
    "        def not_blank(row):\n",
    "            return sum(map(len, row[:6])) > 0\n",
    "\n",
    "    rows = filter(not_blank, values)\n",
    "    if not rows:\n",
    "        print('*** No data found after pruning rows! ***')\n",
    "        return None\n",
    "    \n",
    "    columns = enumerate_duplicates(rows[0])\n",
    "    ncols = len(rows[0])\n",
    "    row_max = max(map(len, rows[1:]))\n",
    "    width = min(ncols, row_max)\n",
    "    return pd.DataFrame(rows[1:], columns=columns[:width])\n",
    "\n",
    "def canonicalise_df(df, source=None):\n",
    "    \"\"\"Initial cleaning of all dataframes\"\"\"\n",
    "    #from pandas._libs.tslib import OutOfBoundsDatetime\n",
    "    if source:\n",
    "        print(\"Canonicalising %s\" % source)\n",
    "    # Standardise names\n",
    "    d = {\n",
    "        'Sample Code':'SampleNumber',\n",
    "        'Sample Number:':'SampleNumber',\n",
    "        'Sample Number':'SampleNumber',\n",
    "        'Sample number':'SampleNumber',\n",
    "        'Sample Num':'SampleNumber',\n",
    "        'Sample Number i.e F0XXX' : 'SampleNumber',\n",
    "        \n",
    "        'Sample Advertised/Acquired/Sold As' : 'SoldAs',\n",
    "        'Sample Sold As' : 'SoldAs',\n",
    "        \n",
    "        'Sample Source' :'SampleSource',\n",
    "\n",
    "        'User Suspicion' :'UserSuspicion',\n",
    "\n",
    "        'Sample Form' :'SampleForm',\n",
    "\n",
    "        'Has the Service User or a close friend tried this batch?' : 'AlreadyTried',\n",
    "\n",
    "        'Your initials' : 'Tester',\n",
    "        'Your name and first initial' : 'Tester',\n",
    "        'Your name and surname initial' : 'Tester'\n",
    "    }\n",
    "    df.rename(columns=d, inplace=True)\n",
    "    \n",
    "    def fix_timestamp(x):\n",
    "        \"\"\"Horror to fix mixed date formats\"\"\"\n",
    "        return pd.to_datetime(str(x), format='%d/%m/%Y %H:%M:%S')\n",
    "#         try:\n",
    "#             x = pd.to_datetime(x)\n",
    "#         except:\n",
    "#             try:\n",
    "#                 # '12/08/2018 12:26:15'\n",
    "#                 x = pd.to_datetime(x, format='%d/%m/%Y %H:%M:%S')\n",
    "#             except:\n",
    "#                 #'Thu 9/08 - 12:19'\n",
    "#                 x = pd.to_datetime(x, format='%a %m/%y - %H:%M')\n",
    "#         return x\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df.loc[:, 'Timestamp'] = df['Timestamp'].map(fix_timestamp)\n",
    "    df.loc[:, 'SampleNumber'] = df['SampleNumber'].apply(fix_sample_number)\n",
    "    df.dropna(subset=['SampleNumber'])\n",
    "    #df.sort_values(['Sample Number'], ascending=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_data(service, SPREADSHEET_ID):\n",
    "\n",
    "    CATALOG_RANGE = 'Catalog!A:R'\n",
    "    FTIR_RANGE = 'FTIR!A:X'\n",
    "    REAGENT_RANGE = 'Reagent!A:W'\n",
    "    MLA_RANGE = 'MLA!A:R'\n",
    "    HR_RANGE = 'Interventions!A:BJ'\n",
    "\n",
    "    #service = gsheets_service()\n",
    "\n",
    "    df_catalog = get_df(service, SPREADSHEET_ID, CATALOG_RANGE)\n",
    "    df_catalog = canonicalise_df(df_catalog, source='catalog')\n",
    "    df_ftir = get_df(service, SPREADSHEET_ID, FTIR_RANGE)\n",
    "    df_ftir = canonicalise_df(df_ftir, source='ftir')\n",
    "    df_reagent = get_df(service, SPREADSHEET_ID, REAGENT_RANGE)\n",
    "    df_reagent = canonicalise_df(df_reagent, source='reagent')\n",
    "    df_mla = get_df(service, SPREADSHEET_ID, MLA_RANGE, mla=True)\n",
    "    df_mla = canonicalise_df(df_mla, source='mla')\n",
    "    try:\n",
    "        df_hr = get_df(service, SPREADSHEET_ID, HR_RANGE)\n",
    "    except ValueError:\n",
    "        df_hr = None\n",
    "    if df_hr is not None:\n",
    "        df_hr = canonicalise_df(df_hr, source='hr')\n",
    "\n",
    "    df = DataFrames()\n",
    "    df.catalog=df_catalog\n",
    "    df.ftir=df_ftir\n",
    "    df.reagent=df_reagent\n",
    "    df.mla=df_mla\n",
    "    df.hr=df_hr\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "BOOMTOWN2018_SPREADSHEET_ID = '1RiA-FwG_954Ger2VPsOSA3JLh-7sEoTYr40eVS0mp24'\n",
    "MADE2018_SPREADSHEET_ID = '1daXdyL6uL8qnMsEsP0RLZE9nDzt6J7Zr1ygQdguvi-E'\n",
    "BOARDMASTERS2018_SPREADSHEET_ID = '1U1lhUWLazDBN-wb2eZM8YV674f46npVfQK3XUVZjPow'\n",
    "SW42018_SPREADSHEET_ID = '1agpMmJ9XukeWXS5_mwrDSKeshUaFtYwOzsPiR1DKsPU'\n",
    "LOSTVILLAGE2018_SPREADSHEET_ID = '1OL0gyXrpZnJ8e7yR7eF6S2OaBYBiPDoVp5xGpdK4wlA'\n",
    "BESTIVAL2018_SPREADSHEET_ID = '184qudGcw4PB0SMtOo0ZBDtckeGaH0RCLUXbA-u3BiHE'\n",
    "YNOT2018_SPREADSHEET_ID = '1D01cj-Mra06TuoG_MsKuLq9OdtvKzrvRdiE255po_ag'\n",
    "TRUCKFEST2018_SPREADSHEET_ID = '1sGG9WJxKyD2CGUjzJAXul3g9hVnRz6HbTiqKV5cUAyA'\n",
    "LSTD2018_SPREADSHEET_ID = '1R8YqDnrhvuVMwPFShwaaAUIyCXQMeozA230OXsFsDQM'\n",
    "KENDALCALLING2018_SPREADSHEET_ID = '16-PfwBOaUxwod3X75LGk1VAjBblkNsTJpCsX825aghI'\n",
    "PARKLIFE2018_SPREADSHEET_ID = '1oO5sHcUhUn_7M1Hap73sOZHNEfWFMcDkQuWDRFf4d-w'\n",
    "\n",
    "\n",
    "data = {}\n",
    "service = gsheets_service()\n",
    "print \"PROCESSING BOOMTOWN\"\n",
    "data['boomtown'] = get_data(service, BOOMTOWN2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING BOARDMASTERS\"\n",
    "# data['boardmasters'] = get_data(service, BOARDMASTERS2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING MADE\"\n",
    "# data['made'] = get_data(service, MADE2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING SW4\"\n",
    "# data['sw4'] = get_data(service, SW42018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING LOST VILLAGE\"\n",
    "# data['lostvillage'] = get_data(service, LOSTVILLAGE2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING BESTIVAL\"\n",
    "# data['bestival'] = get_data(service, BESTIVAL2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING YNOT\"\n",
    "# data['ynot'] = get_data(service, YNOT2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING TRUCKFEST\"\n",
    "# data['truckfest'] = get_data(service, TRUCKFEST2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING LSTD\"\n",
    "# data['lstd'] = get_data(service, LSTD2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING KENDAL CALLING\"\n",
    "# data['kc'] = get_data(service, KENDALCALLING2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING PARKLIFE\"\n",
    "# data['parklife'] = get_data(service, PARKLIFE2018_SPREADSHEET_ID)\n",
    "\n",
    "import pickle\n",
    "with open('foo_multi.pkl','w') as w:\n",
    "    pickle.dump(data, w)\n",
    "    \n",
    "dfs = data['boomtown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 47 duplicated catalog SampleNumbers ['F0109', 'F0076', 'F0024', 'F0158', 'F0159', 'F0255', 'F0275', 'F0344', 'F0373', 'F0446', 'F0690', 'F0579', 'F0833', 'F0739', 'F0939', 'F0870', 'F0934', 'F0930', 'F0873', 'F0857', 'F0945', 'F0858', 'F0853', 'F0943', 'F0944', 'F0855', 'F0848', 'F0695', 'F0862', 'F0831', 'F0852', 'F0889', 'F0846', 'F0904', 'F0922', 'F1122', 'F0976', 'F1170', 'F0012', 'F1207', 'F1227', 'F1210', 'F1585', 'F1665', 'F1660', 'F1856', 'F1873'] ###\n",
      "### 48 duplicated FTIR SampleNumbers ['F0017', 'F0247', 'F0266', 'F0376', 'F0158', 'F0019', 'F0019', 'F0546', 'F0446', 'F0005', 'F0599', 'F0659', 'F0688', 'F0748', 'F1137', 'F0983', 'F0938', 'F0869', 'F0838', 'F0982', 'F0865', 'F0816', 'F0878', 'F0885', 'F0833', 'F0815', 'F1196', 'F1122', 'F1292', 'F1253', 'F1210', 'F1313', 'F1393', 'F1665', 'F1215', 'F1392', 'F1640', 'F1172', 'F1606', 'F1433', 'F1431', 'F1609', 'F1660', 'F1623', 'F1792', 'F1846', 'F0912', 'F1830'] ###\n",
      "### 7 duplicated reagent SampleNumbers ['F0446', 'F0565', 'F0874', 'F0932', 'F0930', 'F1561', 'F1435'] ###\n",
      "### 59 duplicated HR SampleNumbers ['F0058', 'F0138', 'F0392', 'F0645', 'F0653', 'F0886', 'F0699', 'F0128', 'F0144', 'F0807', 'F0150', 'F0011', 'F0170', 'F1188', 'F0193', 'F0162', 'F0770', 'F0172', 'F0236', 'F0271', 'F0895', 'F0895', 'F0136', 'F0267', 'F0106', 'F0277', 'F1371', 'F0116', 'F0104', 'F0104', 'F0126', 'F0809', 'F0577', 'F1133', 'F0580', 'F1208', 'F0306', 'F0210', 'F1246', 'F0145', 'F0635', 'F0474', 'F0833', 'F0561', 'F1557', 'F0562', 'F0602', 'F0640', 'F0609', 'F1316', 'F1418', 'F1418', 'F0545', 'F0713', 'F0129', 'F1426', 'F1762', 'F0689', 'F1856'] ###\n",
      "Please fix duplicated values\n"
     ]
    }
   ],
   "source": [
    "# with open('foo_multi.pkl') as f:\n",
    "#     data = pickle.load(f)\n",
    "# dfs = data['boomtown']\n",
    "\n",
    "# Check for duplicates\n",
    "catalog_duplicates = dfs.catalog['SampleNumber'].duplicated()\n",
    "if catalog_duplicates.any():\n",
    "    catalog_duplicates = list(dfs.catalog.loc[catalog_duplicates, 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated catalog SampleNumbers %s ###\" % (len(catalog_duplicates), catalog_duplicates))\n",
    "    dfs.catalog[dfs.catalog['SampleNumber'].duplicated(keep=False)].to_csv('catalog_duplicates.csv')\n",
    "else:\n",
    "    catalog_duplicates = None\n",
    "    \n",
    "ftir_duplicates = dfs.ftir['SampleNumber'].duplicated()\n",
    "if ftir_duplicates.any():\n",
    "    ftir_duplicates = list(dfs.ftir.loc[dfs.ftir['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated FTIR SampleNumbers %s ###\" % (len(ftir_duplicates), ftir_duplicates))\n",
    "    dfs.ftir[dfs.ftir['SampleNumber'].duplicated(keep=False)].to_csv('ftir_duplicates.csv')\n",
    "else:\n",
    "    ftir_duplicates = None\n",
    "\n",
    "reagent_duplicates = dfs.reagent['SampleNumber'].duplicated()\n",
    "if reagent_duplicates.any():\n",
    "    reagent_duplicates = list(dfs.reagent.loc[dfs.reagent['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated reagent SampleNumbers %s ###\" % (len(reagent_duplicates), reagent_duplicates))    \n",
    "    dfs.reagent[dfs.reagent['SampleNumber'].duplicated(keep=False)].to_csv('reagent_duplicates.csv', encoding = 'utf-8')\n",
    "else:\n",
    "    reagent_duplicates = None\n",
    "\n",
    "hr_duplicates = None\n",
    "if dfs.hr is not None:\n",
    "    hr_duplicates = dfs.hr['SampleNumber'].duplicated()\n",
    "    if hr_duplicates.any():\n",
    "        hr_duplicates = list(dfs.hr.loc[dfs.hr['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "        print(\"### %d duplicated HR SampleNumbers %s ###\" % (len(hr_duplicates), hr_duplicates))\n",
    "        dfs.hr[dfs.hr['SampleNumber'].duplicated(keep=False)].to_csv('hr_duplicates.csv', encoding = 'utf-8')\n",
    "    else:\n",
    "        hr_duplicates = None\n",
    "\n",
    "mla_duplicates = dfs.mla['SampleNumber'].duplicated()\n",
    "if mla_duplicates.any():\n",
    "    mla_duplicates = list(dfs.mla.loc[dfs.mla['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated MLA SampleNumbers %s ###\" % (len(mla_duplicates), mla_duplicates))\n",
    "    dfs.mla[dfs.mla['SampleNumber'].duplicated(keep=False)].to_csv('mla_duplicates.csv')\n",
    "else:\n",
    "    mla_duplicates = None\n",
    "    \n",
    "if catalog_duplicates or \\\n",
    "    ftir_duplicates or \\\n",
    "    reagent_duplicates or \\\n",
    "    hr_duplicates or \\\n",
    "    mla_duplicates:\n",
    "    outs = 'Please fix duplicated values'\n",
    "    print(outs)\n",
    "#     raise RuntimeError(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphaned FTIR SampleNumbers: ['A1439', 'A1904', 'A1910', 'B0076', 'F00129', 'F0054', 'F0057', 'F0156', 'F0225', 'F0272', 'F0285', 'F0343', 'F0378', 'F0571', 'F0795', 'F0876', 'F0883', 'F0967', 'F0983', 'F1179', 'F1197', 'F1201', 'F1277', 'F1413', 'F1518', 'F1878', 'F1880', 'Z1000']\n",
      "Orphaned Reagent Test SampleNumbers: ['F0225', 'F0526', 'F0983', 'F1437', 'F1819 (or 1827?)', 'Yellow > green', 'Z1000']\n",
      "Orphaned HR SampleNumbers: ['F0054', 'F0154', 'F0156', 'F0225', 'F0272', 'F0285', 'F0378', 'F0612', 'F0616', 'F0795', 'F0876', 'F0883', 'F0967', 'F1076', 'F1179', 'F1201', 'F1880', 'F2901', 'F9999', 'G0024', 'G0037', 'G0153', 'G0242', 'G0420', 'G0652', 'G0811', 'G0875', 'G0877', 'G0878', 'G0981', 'G0983', 'G1216', 'G1228', 'G1229', 'G1284', 'G1312', 'G1398', 'G1441', 'G1572', 'G1686', 'G1699', 'G1703', 'G1833', 'G1859', 'G1860', 'G9999']\n",
      "Orphaned MLA SampleNumbers: ['F0156', 'F0795']\n",
      "Orphaned catalog SampleNumbers: ['F0516', 'F1012', 'F1104', 'F1168', 'F1243', 'F1488', 'F1910', 'R0876']\n",
      "Samples not in FTIR or Reagent: ['F0368', 'F0369', 'F0871', 'F0879', 'F1582', 'F1746', 'F1819']\n",
      "### Please fix orphaned/catalog only samples ###\n"
     ]
    }
   ],
   "source": [
    "# Check there are no SampleNumbers in any of the other spreadsheets that aren't in the cataolog sheet\n",
    "catalog_unique = set(dfs.catalog['SampleNumber'].unique())\n",
    "\n",
    "ftir_unique = set(dfs.ftir['SampleNumber'].unique())\n",
    "ftir_orphan = ftir_unique.difference(catalog_unique)\n",
    "if ftir_orphan:\n",
    "    print(\"Orphaned FTIR SampleNumbers: %s\" % sorted(ftir_orphan))\n",
    "\n",
    "reagent_unique = set(dfs.reagent['SampleNumber'].unique())\n",
    "reagent_orphan = reagent_unique.difference(catalog_unique)\n",
    "if reagent_orphan:\n",
    "    print(\"Orphaned Reagent Test SampleNumbers: %s\" % sorted(reagent_orphan))\n",
    "\n",
    "hr_orphan = None\n",
    "if dfs.hr is not None:\n",
    "    hr_unique = set(dfs.hr['SampleNumber'].unique())\n",
    "    hr_orphan = hr_unique.difference(catalog_unique)\n",
    "    if hr_orphan:\n",
    "        print(\"Orphaned HR SampleNumbers: %s\" % sorted(hr_orphan))\n",
    "    \n",
    "mla_unique = set(dfs.mla['SampleNumber'].unique()).difference(catalog_unique)\n",
    "mla_orphan = mla_unique.difference(catalog_unique)\n",
    "if mla_orphan:\n",
    "    print(\"Orphaned MLA SampleNumbers: %s\" % sorted(mla_orphan))\n",
    "    \n",
    "# Check for any that are only in the catalog\n",
    "outside_catalog = set.union(ftir_unique, reagent_unique, hr_unique, mla_unique)\n",
    "catalog_orphan = catalog_unique.difference(outside_catalog)\n",
    "if catalog_orphan:\n",
    "    print(\"Orphaned catalog SampleNumbers: %s\" % sorted(catalog_orphan))\n",
    "    \n",
    "# Check for any that aren't in FTIR and don't have anything in reagent test\n",
    "ftir_missing = catalog_unique.difference(ftir_unique).difference(reagent_unique).difference(catalog_orphan)\n",
    "if len(ftir_missing):\n",
    "    print(\"Samples not in FTIR or Reagent: %s\" % sorted(ftir_missing))\n",
    "\n",
    "all_unique = copy.copy(ftir_unique)\n",
    "all_unique.update(reagent_unique, hr_unique, mla_unique)\n",
    "if (all_unique or catalog_only):\n",
    "    outs = \"### Please fix orphaned/catalog only samples ###\"\n",
    "    print(outs)\n",
    "    #raise RuntimeError(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    sample_form_d = { 'pill' : ['Ecstasy Tablet',\n",
    "                                'ecstasy pill',\n",
    "                                'ecstacy pill',\n",
    "                                'Non-pharmaceutical tablet (ecstasy etc)',\n",
    "                                'other recreational pill',\n",
    "                                 'Whole pill',\n",
    "                                'Other pill',\n",
    "                                'Pharmaceutical'],\n",
    "                  'partial pill' : ['Partial ecstasy pill',\n",
    "                                    'Partial 2C-B pill',\n",
    "                                    'Crushed tablet'],\n",
    "                  'powder' : ['Powder/capsule/bomb/crystal',\n",
    "                              'Powder or crushed pill',\n",
    "                              'Crystal, Capsule or Powder'],\n",
    "                  'liquid' : ['*Cannabinoid liquid',\n",
    "                               '*Viscous liquid',\n",
    "                              'Dissolved in Propylene Glycol',\n",
    "                              'Oil'],\n",
    "                   'tab' : ['blotter', 'LSD Tab']\n",
    "                      }\n",
    "\n",
    "\n",
    "    # Firstly convert all columns to lower case and remove any spaces\n",
    "    def lower(value):\n",
    "        if type(value) in [str, unicode]:\n",
    "            value = value.strip().lower()\n",
    "        return value\n",
    "\n",
    "    for column in ['SampleForm']:\n",
    "        df[column] = df[column].map(lower, na_action='ignore')\n",
    "    \n",
    "    replace_d = {}\n",
    "    for column in ['SampleForm']:\n",
    "        replace_d[column] = {}\n",
    "        for drug, names in sample_form_d.items():\n",
    "            for name in names:\n",
    "                replace_d[column][name.lower()] = drug\n",
    "    \n",
    "    # Replace values\n",
    "    df.replace(replace_d, inplace=True)\n",
    "    return df\n",
    "    \n",
    "dfs.catalog = clean_df(dfs.catalog)\n",
    "dfs.ftir = clean_df(dfs.ftir)\n",
    "dfs.reagent = clean_df(dfs.reagent)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ftir <-> catalog\n",
    "\n",
    "incorrect_duplicates = []\n",
    "for each duplicate sample number:\n",
    "    see if one is definiitively wrong and add to list\n",
    "\n",
    "for each incorrect duplicate:\n",
    "    for each orphan:\n",
    "        see if this orphan could match the duplicate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog SampleNumber F0109 duplicate (line: 31) DIFFERENT FTIR sample (line: 82)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 12:54:36\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:36:24\n",
      "Catalog SampleNumber F0109 duplicate (line: 47) DIFFERENT FTIR sample (line: 82)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 13:06:16\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:36:24\n",
      "Catalog SampleNumber F0076 duplicate (line: 22) DIFFERENT FTIR sample (line: 69)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-09 12:45:08\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:33:48\n",
      "Catalog SampleNumber F0076 duplicate (line: 49) DIFFERENT FTIR sample (line: 69)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 13:08:00\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:33:48\n",
      "Catalog SampleNumber F0024 duplicate (line: 4) DIFFERENT FTIR sample (line: 22)\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 12:27:47\n",
      "['powder', u'Cocaine', u'No'] 2018-08-09 14:51:38\n",
      "Catalog SampleNumber F0024 duplicate (line: 76) DIFFERENT FTIR sample (line: 22)\n",
      "['powder', u'Cocaine', u'No'] 2018-08-09 13:56:29\n",
      "['powder', u'Cocaine', u'No'] 2018-08-09 14:51:38\n",
      "Catalog SampleNumber F0158 duplicate (line: 155) DIFFERENT FTIR sample (line: 153)\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 15:55:51\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 16:36:25\n",
      "Catalog SampleNumber F0158 duplicate (line: 155) DIFFERENT FTIR sample (line: 418)\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 15:55:51\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 21:27:48\n",
      "Catalog SampleNumber F0158 duplicate (line: 174) MATCHES FTIR sample (line: 153)\n",
      "Catalog SampleNumber F0158 duplicate (line: 174) DIFFERENT FTIR sample (line: 418)\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 16:21:00\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 21:27:48\n",
      "Catalog SampleNumber F0159 duplicate (line: 150) DIFFERENT FTIR sample (line: 179)\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 15:40:53\n",
      "['powder', u'Ketamine', u'No'] 2018-08-09 17:02:03\n",
      "Catalog SampleNumber F0159 duplicate (line: 199) MATCHES FTIR sample (line: 179)\n",
      "Catalog SampleNumber F0255 duplicate (line: 220) DIFFERENT FTIR sample (line: 246)\n",
      "['powder', u'Psilocybin', u'No'] 2018-08-09 16:58:05\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-09 18:28:43\n",
      "Catalog SampleNumber F0255 duplicate (line: 243) DIFFERENT FTIR sample (line: 246)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-09 17:15:46\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-09 18:28:43\n",
      "Catalog SampleNumber F0275 duplicate (line: 284) DIFFERENT FTIR sample (line: 305)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-09 17:54:24\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-09 19:34:15\n",
      "Catalog SampleNumber F0275 duplicate (line: 310) DIFFERENT FTIR sample (line: 305)\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 18:06:42\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-09 19:34:15\n",
      "Catalog SampleNumber F0344 duplicate (line: 286) DIFFERENT FTIR sample (line: 303)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-09 17:54:57\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-09 19:32:10\n",
      "Catalog SampleNumber F0344 duplicate (line: 342) DIFFERENT FTIR sample (line: 303)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-09 18:26:30\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-09 19:32:10\n",
      "Catalog SampleNumber F0373 duplicate (line: 363) DIFFERENT FTIR sample (line: 380)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 18:40:24\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 20:41:52\n",
      "Catalog SampleNumber F0373 duplicate (line: 407) DIFFERENT FTIR sample (line: 380)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-09 19:16:35\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 20:41:52\n",
      "Catalog SampleNumber F0446 duplicate (line: 475) DIFFERENT FTIR sample (line: 471)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 13:00:44\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 13:25:19\n",
      "Catalog SampleNumber F0446 duplicate (line: 475) DIFFERENT FTIR sample (line: 516)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 13:00:44\n",
      "['pill', u\"didn't answer\", u'No'] 2018-08-10 14:35:20\n",
      "Catalog SampleNumber F0446 duplicate (line: 522) DIFFERENT FTIR sample (line: 471)\n",
      "['pill', u'N/A', u'No'] 2018-08-10 14:13:59\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 13:25:19\n",
      "Catalog SampleNumber F0446 duplicate (line: 522) DIFFERENT FTIR sample (line: 516)\n",
      "['pill', u'N/A', u'No'] 2018-08-10 14:13:59\n",
      "['pill', u\"didn't answer\", u'No'] 2018-08-10 14:35:20\n",
      "Catalog SampleNumber F0690 duplicate (line: 580) MATCHES FTIR sample (line: 561)\n",
      "Catalog SampleNumber F0690 duplicate (line: 583) MATCHES FTIR sample (line: 561)\n",
      "Catalog SampleNumber F0579 duplicate (line: 511) DIFFERENT FTIR sample (line: 503)\n",
      "['pill', u'2C-B', u'Yes'] 2018-08-10 13:56:06\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 14:19:34\n",
      "Catalog SampleNumber F0579 duplicate (line: 603) DIFFERENT FTIR sample (line: 503)\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-10 15:35:52\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 14:19:34\n",
      "Catalog SampleNumber F0833 duplicate (line: 724) DIFFERENT FTIR sample (line: 935)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 16:48:42\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 21:53:33\n",
      "Catalog SampleNumber F0833 duplicate (line: 724) DIFFERENT FTIR sample (line: 970)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 16:48:42\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 22:47:41\n",
      "Catalog SampleNumber F0833 duplicate (line: 730) DIFFERENT FTIR sample (line: 935)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 16:50:14\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 21:53:33\n",
      "Catalog SampleNumber F0833 duplicate (line: 730) DIFFERENT FTIR sample (line: 970)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 16:50:14\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 22:47:41\n",
      "Catalog SampleNumber F0739 duplicate (line: 645) DIFFERENT FTIR sample (line: 660)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 15:47:07\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 16:54:49\n",
      "Catalog SampleNumber F0739 duplicate (line: 752) DIFFERENT FTIR sample (line: 660)\n",
      "['pill', u'', u'No'] 2018-08-10 16:58:33\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 16:54:49\n",
      "Catalog SampleNumber F0939 duplicate (line: 844) DIFFERENT FTIR sample (line: 885)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 17:40:10\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 20:50:59\n",
      "Catalog SampleNumber F0939 duplicate (line: 852) DIFFERENT FTIR sample (line: 885)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 17:44:06\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 20:50:59\n",
      "Catalog SampleNumber F0870 duplicate (line: 842) DIFFERENT FTIR sample (line: 748)\n",
      "['powder', u'MDMA', u'No'] 2018-08-10 17:39:41\n",
      "['powder', u'MDMA', u'No'] 2018-08-10 18:18:59\n",
      "Catalog SampleNumber F0870 duplicate (line: 853) DIFFERENT FTIR sample (line: 748)\n",
      "['powder', u'MDMA', u'No'] 2018-08-10 17:44:29\n",
      "['powder', u'MDMA', u'No'] 2018-08-10 18:18:59\n",
      "Catalog SampleNumber F0934 duplicate (line: 840) DIFFERENT FTIR sample (line: 747)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 17:39:17\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 18:16:54\n",
      "Catalog SampleNumber F0934 duplicate (line: 855) DIFFERENT FTIR sample (line: 747)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 17:44:56\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 18:16:54\n",
      "Catalog SampleNumber F0873 duplicate (line: 838) DIFFERENT FTIR sample (line: 745)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 17:38:43\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 18:15:08\n",
      "Catalog SampleNumber F0873 duplicate (line: 858) MATCHES FTIR sample (line: 745)\n",
      "Catalog SampleNumber F0857 duplicate (line: 837) DIFFERENT FTIR sample (line: 859)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 17:38:10\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 19:58:45\n",
      "Catalog SampleNumber F0857 duplicate (line: 860) DIFFERENT FTIR sample (line: 859)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 17:46:08\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 19:58:45\n",
      "Catalog SampleNumber F0945 duplicate (line: 834) DIFFERENT FTIR sample (line: 850)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 17:37:21\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 19:50:54\n",
      "Catalog SampleNumber F0945 duplicate (line: 862) DIFFERENT FTIR sample (line: 850)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 17:47:02\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 19:50:54\n",
      "Catalog SampleNumber F0858 duplicate (line: 831) DIFFERENT FTIR sample (line: 871)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 17:36:47\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 20:07:55\n",
      "Catalog SampleNumber F0858 duplicate (line: 866) DIFFERENT FTIR sample (line: 871)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 17:47:42\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 20:07:55\n",
      "Catalog SampleNumber F0853 duplicate (line: 829) DIFFERENT FTIR sample (line: 867)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 17:36:16\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 20:04:30\n",
      "Catalog SampleNumber F0853 duplicate (line: 868) DIFFERENT FTIR sample (line: 867)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 17:48:16\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 20:04:30\n",
      "Catalog SampleNumber F0943 duplicate (line: 827) DIFFERENT FTIR sample (line: 769)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 17:35:31\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 18:41:10\n",
      "Catalog SampleNumber F0943 duplicate (line: 870) DIFFERENT FTIR sample (line: 769)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 17:48:54\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 18:41:10\n",
      "Catalog SampleNumber F0944 duplicate (line: 824) DIFFERENT FTIR sample (line: 770)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 17:34:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:42:38\n",
      "Catalog SampleNumber F0944 duplicate (line: 871) DIFFERENT FTIR sample (line: 770)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 17:49:29\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:42:38\n",
      "Catalog SampleNumber F0855 duplicate (line: 822) DIFFERENT FTIR sample (line: 773)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 17:33:52\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:43:50\n",
      "Catalog SampleNumber F0855 duplicate (line: 873) DIFFERENT FTIR sample (line: 773)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 17:50:11\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:43:50\n",
      "Catalog SampleNumber F0848 duplicate (line: 820) DIFFERENT FTIR sample (line: 775)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 17:33:07\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 18:45:17\n",
      "Catalog SampleNumber F0848 duplicate (line: 875) DIFFERENT FTIR sample (line: 775)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 17:50:50\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-10 18:45:17\n",
      "Catalog SampleNumber F0695 duplicate (line: 803) DIFFERENT FTIR sample (line: 759)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:21:19\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:34:47\n",
      "Catalog SampleNumber F0695 duplicate (line: 879) DIFFERENT FTIR sample (line: 759)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:53:02\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:34:47\n",
      "Catalog SampleNumber F0862 duplicate (line: 819) DIFFERENT FTIR sample (line: 810)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:32:23\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:20:02\n",
      "Catalog SampleNumber F0862 duplicate (line: 884) DIFFERENT FTIR sample (line: 810)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:54:22\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:20:02\n",
      "Catalog SampleNumber F0831 duplicate (line: 813) DIFFERENT FTIR sample (line: 755)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:27:22\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:31:43\n",
      "Catalog SampleNumber F0831 duplicate (line: 888) DIFFERENT FTIR sample (line: 755)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:55:12\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:31:43\n",
      "Catalog SampleNumber F0852 duplicate (line: 812) DIFFERENT FTIR sample (line: 819)\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-10 17:26:32\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 19:29:11\n",
      "Catalog SampleNumber F0852 duplicate (line: 890) DIFFERENT FTIR sample (line: 819)\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-10 17:56:11\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 19:29:11\n",
      "Catalog SampleNumber F0889 duplicate (line: 811) DIFFERENT FTIR sample (line: 822)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:25:41\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:31:59\n",
      "Catalog SampleNumber F0889 duplicate (line: 892) DIFFERENT FTIR sample (line: 822)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:56:47\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:31:59\n",
      "Catalog SampleNumber F0846 duplicate (line: 809) DIFFERENT FTIR sample (line: 958)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:24:49\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:26:23\n",
      "Catalog SampleNumber F0846 duplicate (line: 894) DIFFERENT FTIR sample (line: 958)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:57:34\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:26:23\n",
      "Catalog SampleNumber F0904 duplicate (line: 808) DIFFERENT FTIR sample (line: 903)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:23:57\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 21:19:05\n",
      "Catalog SampleNumber F0904 duplicate (line: 895) DIFFERENT FTIR sample (line: 903)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:58:19\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 21:19:05\n",
      "Catalog SampleNumber F0922 duplicate (line: 806) DIFFERENT FTIR sample (line: 753)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:23:10\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:29:28\n",
      "Catalog SampleNumber F0922 duplicate (line: 897) DIFFERENT FTIR sample (line: 753)\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:59:17\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:29:28\n",
      "Catalog SampleNumber F1122 duplicate (line: 934) DIFFERENT FTIR sample (line: 949)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:30:17\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:12:19\n",
      "Catalog SampleNumber F1122 duplicate (line: 934) DIFFERENT FTIR sample (line: 1007)\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:30:17\n",
      "['powder', u'Ketamine', u'No'] 2018-08-11 11:14:50\n",
      "Catalog SampleNumber F1122 duplicate (line: 964) DIFFERENT FTIR sample (line: 949)\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:52:45\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:12:19\n",
      "Catalog SampleNumber F1122 duplicate (line: 964) DIFFERENT FTIR sample (line: 1007)\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:52:45\n",
      "['powder', u'Ketamine', u'No'] 2018-08-11 11:14:50\n",
      "Catalog SampleNumber F0976 duplicate (line: 927) DIFFERENT FTIR sample (line: 889)\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:27:12\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 21:00:43\n",
      "Catalog SampleNumber F0976 duplicate (line: 965) DIFFERENT FTIR sample (line: 889)\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 18:55:30\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 21:00:43\n",
      "Catalog SampleNumber F1170 duplicate (line: 973) DIFFERENT FTIR sample (line: 922)\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 19:19:39\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 21:42:11\n",
      "Catalog SampleNumber F1170 duplicate (line: 983) DIFFERENT FTIR sample (line: 922)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 19:26:17\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 21:42:11\n",
      "Catalog SampleNumber F0012 duplicate (line: 41) DIFFERENT FTIR sample (line: 10)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-09 13:03:04\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-09 13:44:45\n",
      "Catalog SampleNumber F0012 duplicate (line: 1031) DIFFERENT FTIR sample (line: 10)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 20:14:33\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-09 13:44:45\n",
      "Catalog SampleNumber F1207 duplicate (line: 1103) DIFFERENT FTIR sample (line: 1093)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 13:23:30\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 13:56:33\n",
      "Catalog SampleNumber F1207 duplicate (line: 1140) DIFFERENT FTIR sample (line: 1093)\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-11 13:54:36\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 13:56:33\n",
      "Catalog SampleNumber F1227 duplicate (line: 1078) DIFFERENT FTIR sample (line: 1120)\n",
      "['powder', u'Found or otherwise not known', u'Yes'] 2018-08-11 13:02:59\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-11 14:21:37\n",
      "Catalog SampleNumber F1227 duplicate (line: 1158) MATCHES FTIR sample (line: 1120)\n",
      "Catalog SampleNumber F1210 duplicate (line: 1169) DIFFERENT FTIR sample (line: 1109)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 14:06:48\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-11 14:11:54\n",
      "Catalog SampleNumber F1210 duplicate (line: 1169) MATCHES FTIR sample (line: 1111)\n",
      "Catalog SampleNumber F1210 duplicate (line: 1171) MATCHES FTIR sample (line: 1109)\n",
      "Catalog SampleNumber F1210 duplicate (line: 1171) DIFFERENT FTIR sample (line: 1111)\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-11 14:07:22\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 14:13:21\n",
      "Catalog SampleNumber F1585 duplicate (line: 1226) DIFFERENT FTIR sample (line: 1203)\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-11 15:02:54\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-11 15:41:13\n",
      "Catalog SampleNumber F1585 duplicate (line: 1231) DIFFERENT FTIR sample (line: 1203)\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-11 15:06:13\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-11 15:41:13\n",
      "Catalog SampleNumber F1665 duplicate (line: 1429) DIFFERENT FTIR sample (line: 1321)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-11 17:44:25\n",
      "['pill', u'MDMA', u'No'] 2018-08-11 17:51:56\n",
      "Catalog SampleNumber F1665 duplicate (line: 1429) DIFFERENT FTIR sample (line: 1366)\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-11 17:44:25\n",
      "['powder', u'MDMA', u'No'] 2018-08-11 19:11:15\n",
      "Catalog SampleNumber F1665 duplicate (line: 1436) MATCHES FTIR sample (line: 1321)\n",
      "Catalog SampleNumber F1665 duplicate (line: 1436) DIFFERENT FTIR sample (line: 1366)\n",
      "['pill', u'MDMA', u'No'] 2018-08-11 17:48:06\n",
      "['powder', u'MDMA', u'No'] 2018-08-11 19:11:15\n",
      "Catalog SampleNumber F1660 duplicate (line: 1433) MATCHES FTIR sample (line: 1318)\n",
      "Catalog SampleNumber F1660 duplicate (line: 1433) DIFFERENT FTIR sample (line: 1477)\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-11 17:45:35\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-12 12:07:18\n",
      "Catalog SampleNumber F1660 duplicate (line: 1438) DIFFERENT FTIR sample (line: 1318)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 17:48:30\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-11 17:49:56\n",
      "Catalog SampleNumber F1660 duplicate (line: 1438) DIFFERENT FTIR sample (line: 1477)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 17:48:30\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-12 12:07:18\n",
      "Catalog SampleNumber F1856 duplicate (line: 1664) DIFFERENT FTIR sample (line: 1631)\n",
      "['powder', u'MDMA', u'No'] 2018-08-12 15:14:49\n",
      "['powder', u'MDMA', u'No'] 2018-08-12 15:56:53\n",
      "Catalog SampleNumber F1856 duplicate (line: 1666) DIFFERENT FTIR sample (line: 1631)\n",
      "['powder', u'MDMA', u'No'] 2018-08-12 15:16:12\n",
      "['powder', u'MDMA', u'No'] 2018-08-12 15:56:53\n",
      "Catalog SampleNumber F1873 duplicate (line: 1679) DIFFERENT FTIR sample (line: 1650)\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-12 15:28:04\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-12 16:16:23\n",
      "Catalog SampleNumber F1873 duplicate (line: 1702) MATCHES FTIR sample (line: 1650)\n"
     ]
    }
   ],
   "source": [
    "def find_duplicate_matches(duplicates, df1, df2, df1_name='DataFrame1', df2_name='DataFrame2'):\n",
    "    duplicate_matches = {}\n",
    "    min_stage_delay = 60 * 1\n",
    "    max_stage_delay = 60 * 30\n",
    "    for sample_number in duplicates:\n",
    "        duplicate_matches[sample_number] = {}\n",
    "        for i, df1_row in enumerate(df1.loc[df1['SampleNumber'] == sample_number].itertuples()):\n",
    "            for j, df2_row in enumerate(df2.loc[df2['SampleNumber'] == sample_number].itertuples()):\n",
    "                i += 1\n",
    "                j += 1\n",
    "                df1_data = [df1_row.SampleForm, df1_row.SoldAs, df1_row.AlreadyTried]\n",
    "                df1_time = df1_row.Timestamp\n",
    "                df1_idx = df1_row.Index + 1\n",
    "                df2_data = [df2_row.SampleForm, df2_row.SoldAs, df2_row.AlreadyTried]\n",
    "                df2_time = df2_row.Timestamp\n",
    "                df2_idx = df2_row.Index + 1            \n",
    "                delta_t = (df2_time - df1_time).seconds\n",
    "                if df1_data == df2_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                    print(\"%s SampleNumber %s duplicate (line: %d) MATCHES %s sample (line: %d)\" % \\\n",
    "                          (df1_name, sample_number, df1_idx, df2_name, df2_idx))\n",
    "                    duplicate_matches[sample_number][df1_row.Index] = True\n",
    "                else:\n",
    "                    print(\"%s SampleNumber %s duplicate (line: %d) DIFFERENT %s sample (line: %d)\\n%s %s\\n%s %s\" % \\\n",
    "                          (df1_name, sample_number, df1_idx, df2_name, df2_idx,\n",
    "                           df1_data, df1_time,\n",
    "                           df2_data, df2_time))\n",
    "                    duplicate_matches[sample_number][df1_row.Index] = False\n",
    "    return duplicate_matches\n",
    "\n",
    "catalog_duplicate_matches = find_duplicate_matches(catalog_duplicates, dfs.catalog, dfs.ftir, df1_name='Catalog', df2_name='FTIR')\n",
    "\n",
    "#duplicate_matches = find_duplicate_matches(ftir_duplicates, dfs.ftir, dfs.catalog, df1_name='FTIR', df2_name='Catalog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphan F0156 could be match for duplicate F0629 (line: 154)\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 15:53:38\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 16:04:31\n"
     ]
    }
   ],
   "source": [
    "def match_orphans_to_duplicates(df1_orphans, duplicate_matches, df1, df2):\n",
    "    for orphan_sample_number in df1_orphans:\n",
    "        df1_data = df1.loc[df1['SampleNumber'] == orphan_sample_number, ['SampleForm', 'SoldAs', 'AlreadyTried', 'Timestamp']]\n",
    "        df1_data = df1_data.values.tolist()[0]\n",
    "        df1_time = df1_data.pop()\n",
    "        for sample_number, indexd in duplicate_matches.items():\n",
    "            for k, v in indexd.items():\n",
    "                if not v:\n",
    "                    df2_data = dfs.catalog.iloc[k][['SampleForm', 'SoldAs', 'AlreadyTried', 'Timestamp']].values.tolist()\n",
    "                    df2_time = df2_data.pop()\n",
    "                    delta_t = (df1_time - df2_time).seconds\n",
    "                    if df2_data == df1_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                        print \"Orphan {} could be match for duplicate {} (line: {})\\n{} {}\\n{} {}\".format(orphan_sample_number,\n",
    "                                                                                                  sample_number, k+1,\n",
    "                                                                                                  df2_data, df2_time,\n",
    "                                                                                                  df1_data, df1_time)\n",
    "\n",
    "match_orphans_to_duplicates(ftir_orphan, duplicate_matches, dfs.ftir, dfs.catalog)\n",
    "# match_orphans_to_duplicates(catalog_orphan, duplicate_matches, dfs.catalog, dfs.ftir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up catalog\n",
    "# Drop all unwanted columns\n",
    "\n",
    "#  or 'Your initials'\n",
    "l = set(['Your initials',\n",
    "         'Your name and first initial',\n",
    "         'Which device was a photo taken with? Who does it belong to?',\n",
    "         'Is a breakline present?',\n",
    "         'Unusual appearance'\n",
    "        ])\n",
    "\n",
    "to_drop = set(dfs.catalog.columns).intersection(l)\n",
    "dfs.catalog.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "d = {\n",
    "    'Timestamp' : 'Catalog timestamp',\n",
    "    'Sample Advertised/Acquired/Sold As': 'Catalog_SoldAs',\n",
    "    'Sample Form' : 'Catalog_Form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'Catalog_Tried',\n",
    "    'What is the mass? (mg)': 'FullPillMass',\n",
    "    'What is the shape of the pill?': 'PillShape',\n",
    "    'What is the logo?': 'PillLogo',\n",
    "    'What colour is the pill?': 'PillColour'\n",
    "}\n",
    "dfs.catalog.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('COLS ', Index([                                                           u'Timestamp',\n",
      "                                                              u'Sample Number',\n",
      "                                                                     u'Tester',\n",
      "                                                                    u'Sold As',\n",
      "                                                                u'Sample Form',\n",
      "                                                              u'Already Tried',\n",
      "                                                             u'User Suspicion',\n",
      "                                                         u'Substance detected',\n",
      "                                                             u'Hit Confidence',\n",
      "                                                          u'Compound detected',\n",
      "                                                           u'Hit Confidence.1',\n",
      "                                                                 u'Brief Note',\n",
      "                           u'Is anything detected after subtraction analysis?',\n",
      "                                            u'Compound detected (Subtraction)',\n",
      "                                                           u'Hit Confidence.2',\n",
      "                                                       u'Substance detected.1',\n",
      "                                                           u'Hit Confidence.3',\n",
      "                                                               u'Brief Note.1',\n",
      "                                                             u'Next action(s)',\n",
      "                                                      u'Substance(s) detected',\n",
      "                                           u'\"Strength\" of powdered substance',\n",
      "       u'Does the substance detected match the substance that was advertised?',\n",
      "                                             u'Note for harm reduction worker',\n",
      "                                                            u'Send to HR team'],\n",
      "      dtype='object'))\n",
      "('SS ', 1691    N-Ethylpentylone\n",
      "1692    N-Ethylpentylone\n",
      "1694    N-Ethylpentylone\n",
      "1696             Cocaine\n",
      "0                   MDMA\n",
      "Name: Substance detected, dtype: object)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_ftir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f76c2c2a13ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_ftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Copy values from 'Compound detected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Brief Note.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ftir' is not defined"
     ]
    }
   ],
   "source": [
    "# For FTIR columns need to merge the data from the 'Compound detected', 'Hit Confidence.1' columns into the\n",
    "# 'Substance detected', 'Hit Confidence' column where the substance detected was 'other'\n",
    "print(\"COLS \",dfs.ftir.columns)\n",
    "print(\"SS \",dfs.ftir['Substance detected'][:5])\n",
    "mask = dfs.ftir['Substance detected'] != 'Other'\n",
    "dfs.ftir['Substance detected'].where(mask, dfs.ftir['Compound detected'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence'].where(mask, dfs.ftir['Hit Confidence.1'], inplace=True)\n",
    "dfs.ftir.drop(['Compound detected', 'Hit Confidence.1', 'Brief Note'], axis=1, inplace=True)\n",
    "\n",
    "mask = dfs.ftir['Compound detected (Subtraction)'] != 'Other'\n",
    "dfs.ftir['Compound detected (Subtraction)'].where(mask, df_ftir['Substance detected.1'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence.2'].where(mask, dfs.ftir['Hit Confidence.3'], inplace=True)\n",
    "dfs.ftir.drop(['Substance detected.1', 'Hit Confidence.3', 'Brief Note.1'], axis=1, inplace=True)\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['Your name and surname initial',\n",
    "     'User Suspicion',\n",
    "     'Is anything detected after subtraction analysis?',\n",
    "     'Analysis required', \n",
    "     'Next action(s)',\n",
    "     'Send to HR team'\n",
    "    ]\n",
    "#'Note for harm reduction worker'\n",
    "to_drop = set(dfs.ftir.columns).intersection(l)\n",
    "dfs.ftir.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'FTIR timestamp',\n",
    "    'Sample Sold As': 'FTIR Sold As',\n",
    "    'Sample Form' : 'FTIR form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'FTIR tried',\n",
    "    'Substance(s) detected' : 'FTIR final result',\n",
    "    'Substance detected' : 'FTIR result1',\n",
    "    'Hit Confidence' :  'FTIR hit1',\n",
    "    'Is anything detected after subtraction analysis?' : 'FTIR subtraction positive',\n",
    "    'Compound detected (Subtraction)' :  'FTIR result2',\n",
    "    'Hit Confidence.2' :  'FTIR hit2',\n",
    "    '\"Strength\" of powdered substance' : 'FTIR Powder Strength',\n",
    "    'Does the substance detected match the substance that was advertised?' : 'FTIR Matches Sold As',\n",
    "}\n",
    "dfs.ftir.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up HR form\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['HR worker name:']\n",
    "dfs.hr.drop(l, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'HR timestamp',\n",
    "    'You submitted a substance for analysis. What were you told it was when you got it?': 'HR Sold as',\n",
    "    'Had you already tried this substance before getting it tested?': 'HR tried',\n",
    "    'What was your first sample number at this event? Did you take a photo or keep the ticket?': 'Previous Sample Number'\n",
    "}\n",
    "dfs.hr.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Catalog and FTIR data frames\n",
    "df_all = pd.merge(dfs.catalog, dfs.ftir, how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in any reagent test data\n",
    "df_all = pd.merge(df_all, dfs.reagent[['Sample Number', 'Reagent Result']], how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in any pill strength data\n",
    "df_all = pd.merge(df_all, dfs.mla[['Sample Number', 'MDMA / tablet (mg)', '% MDMA content']], how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in HR data\n",
    "df_all = pd.merge(df_all, dfs.hr, how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix column orders\n",
    "prefix = ['Sample Number',\n",
    "          'Catalog timestamp', 'FTIR timestamp', 'HR timestamp',\n",
    "          'Catalog Sold As', 'FTIR Sold As','HR Sold as', \n",
    "          'Catalog form', 'FTIR form',\n",
    "          'Catalog tried', 'FTIR tried', 'HR tried']\n",
    "columns = [c for c in df_all.columns if c not in prefix]\n",
    "columns = prefix + columns\n",
    "df_all = df_all[columns]\n",
    "df_all.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
