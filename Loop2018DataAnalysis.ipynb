{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues with MADE dataset:\n",
    "FTIR\n",
    "* Dodgy sample numbers\n",
    "* 2 Hit confidence columns\n",
    "* 2 substance detected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "def fix_sample_number(x):\n",
    "    \"\"\"Make sure all samples numbers are of form: AXXX (where A is one of A, F, W and X is a digit)\"\"\"\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return x # leave NaN's alone\n",
    "    if (isinstance(x, str) or isinstance(x, unicode)) and len(x) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        sn = int(x)\n",
    "        sn = 'F{:04d}'.format(int(x))\n",
    "    except ValueError:\n",
    "        # Assume string so make sure it's of the right format\n",
    "        sn = str(x).capitalize()\n",
    "    if sn[0] not in ['A', 'F', 'W'] or len(x) != 5:\n",
    "        print(\"!!! Bad ID %s\" % sn)\n",
    "    return sn\n",
    "\n",
    "def now():\n",
    "    return datetime.datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "\n",
    "def enumerate_duplicates(row):\n",
    "    \"\"\"Append a counter to duplicate labels\"\"\"\n",
    "    SEPARATOR = '.'\n",
    "    duplicates = {}\n",
    "    updated_row = []\n",
    "    for r in row:\n",
    "        count = duplicates.get(r, 0)\n",
    "        if count > 0:\n",
    "            label = \"{}{}{}\".format(r, SEPARATOR, count)\n",
    "        else:\n",
    "            label = r\n",
    "        updated_row.append(label)\n",
    "        duplicates[r] = count + 1\n",
    "    return updated_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ftir_csv = 'MADE/FTIR Analysis Data Recording Form.csv'\n",
    "catalog_csv = 'MADE/Sample Cataloguing Form.csv'\n",
    "reagent_csv = 'MADE/Reagent Outcomes.csv'\n",
    "hr_csv = 'MADE/MADE MAST Intervention Questionnaire.csv'\n",
    "\n",
    "date_cols = ['Timestamp']\n",
    "df_ftir = pd.read_csv(ftir_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_catalog = pd.read_csv(catalog_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_reagent = pd.read_csv(reagent_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_hr = pd.read_csv(hr_csv, engine=\"python\", parse_dates=date_cols)\n",
    "\n",
    "mla_excel = 'MADE/MADE - Loop 2018 event results sheet_.xlsx'\n",
    "df_mla = pd.read_excel(mla_excel, sheetname='MLA', header=1)\n",
    "\n",
    "# Sort out column names\n",
    "df_reagent.rename(columns={'Sample Code':'Sample Number', 'Substance(s) detected' : 'Reagent Result'}, inplace=True)\n",
    "df_hr.rename(columns={'Sample Number:':'Sample Number'}, inplace=True)\n",
    "df_mla.rename(columns={'Sample Num':'Sample Number'}, inplace=True)\n",
    "\n",
    "# Make all sample numbers a 4-digit code starting with F\n",
    "df_ftir['Sample Number'] = df_ftir['Sample Number'].apply(fix_sample_number)\n",
    "df_catalog['Sample Number'] = df_catalog['Sample Number'].apply(fix_sample_number)\n",
    "df_reagent['Sample Number'] = df_reagent['Sample Number'].apply(fix_sample_number)\n",
    "df_hr['Sample Number'] = df_hr['Sample Number'].apply(fix_sample_number)\n",
    "df_mla['Sample Number'] = df_mla['Sample Number'].apply(fix_sample_number)\n",
    "\n",
    "# Prune down MLA to valid sample numbers\n",
    "df_mla = df_mla[df_mla['Sample Number'].notnull()]\n",
    "\n",
    "DataFrames = namedtuple('DataFrames', ['catalog', 'ftir', 'reagent','mla', 'hr'])\n",
    "dfs = DataFrames(\n",
    "    catalog=df_catalog,\n",
    "    ftir=df_ftir,\n",
    "    reagent=df_reagent,\n",
    "    mla=df_mla,\n",
    "    hr=df_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING BOOMTOWN\n",
      "Canonicalising catalog\n",
      "!!! Bad ID R0876\n",
      "Canonicalising ftir\n",
      "!!! Bad ID F00129\n",
      "!!! Bad ID F0005\n",
      "!!! Bad ID Z1000\n",
      "!!! Bad ID B0076\n",
      "Canonicalising reagent\n",
      "!!! Bad ID Z1000\n",
      "!!! Bad ID Yellow > green\n",
      "!!! Bad ID F1819 (or 1827?)\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "!!! Bad ID G0037\n",
      "!!! Bad ID G0242\n",
      "!!! Bad ID G0153\n",
      "!!! Bad ID G0024\n",
      "!!! Bad ID G0652\n",
      "!!! Bad ID G9999\n",
      "!!! Bad ID G0877\n",
      "!!! Bad ID G0878\n",
      "!!! Bad ID G0811\n",
      "!!! Bad ID G1441\n",
      "!!! Bad ID G1216\n",
      "!!! Bad ID G1228\n",
      "!!! Bad ID G1229\n",
      "!!! Bad ID G1398\n",
      "!!! Bad ID G1284\n",
      "!!! Bad ID G1572\n",
      "!!! Bad ID G0875\n",
      "!!! Bad ID G1833\n",
      "!!! Bad ID G1703\n",
      "!!! Bad ID G1860\n",
      "!!! Bad ID G1859\n",
      "!!! Bad ID G1699\n",
      "!!! Bad ID G1686\n",
      "!!! Bad ID G1312\n",
      "!!! Bad ID G0420\n",
      "!!! Bad ID G0983\n",
      "!!! Bad ID G0981\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = 'raise'\n",
    "\n",
    "# Need to define in main or we can't pickle the data objects\n",
    "DataFrames = namedtuple('DataFrames', ['catalog', 'ftir', 'reagent','mla', 'hr'])\n",
    "\n",
    "def gsheets_service():\n",
    "    from googleapiclient.discovery import build\n",
    "    from httplib2 import Http\n",
    "    from oauth2client import file, client, tools\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    CREDS_FILE = '/opt/random/MADE/JensDataExportJupyter_client_secret.json'\n",
    "    SCOPES = 'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        import argparse\n",
    "        flags = argparse.ArgumentParser(parents=[tools.argparser]).parse_args([])\n",
    "        flow = client.flow_from_clientsecrets(CREDS_FILE, SCOPES)\n",
    "        creds = tools.run_flow(flow, store, flags)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "    return service\n",
    "\n",
    "def get_df(service, SPREADSHEET_ID, SS_RANGE, mla=False):\n",
    "    # Call the Sheets API\n",
    "    result = service.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                                range=SS_RANGE).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('*** No data found ***')\n",
    "        return None\n",
    "\n",
    "    # mla has irrelevant stuff in columns 1 and 3 and sample numbers in first column\n",
    "    if mla:\n",
    "        values.pop(0)\n",
    "        values.pop(1)\n",
    "        def not_blank(row):\n",
    "            return len(row[0]) > 0       \n",
    "    else:\n",
    "        def not_blank(row):\n",
    "            return sum(map(len, row[:6])) > 0\n",
    "\n",
    "    rows = filter(not_blank, values)\n",
    "    if not rows:\n",
    "        print('*** No data found after pruning rows! ***')\n",
    "        return None\n",
    "    \n",
    "    columns = enumerate_duplicates(rows[0])\n",
    "    ncols = len(rows[0])\n",
    "    row_max = max(map(len, rows[1:]))\n",
    "    width = min(ncols, row_max)\n",
    "    return pd.DataFrame(rows[1:], columns=columns[:width])\n",
    "\n",
    "def canonicalise_df(df, source=None):\n",
    "    \"\"\"Initial cleaning of all dataframes\"\"\"\n",
    "    #from pandas._libs.tslib import OutOfBoundsDatetime\n",
    "    if source:\n",
    "        print(\"Canonicalising %s\" % source)\n",
    "    # Standardise names\n",
    "    d = {\n",
    "        'Sample Code':'SampleNumber',\n",
    "        'Sample Number:':'SampleNumber',\n",
    "        'Sample Number':'SampleNumber',\n",
    "        'Sample number':'SampleNumber',\n",
    "        'Sample Num':'SampleNumber',\n",
    "        'Sample Number i.e F0XXX' : 'SampleNumber',\n",
    "        \n",
    "        'Sample Advertised/Acquired/Sold As' : 'SoldAs',\n",
    "        'Sample Sold As' : 'SoldAs',\n",
    "        \n",
    "        'Sample Source' :'SampleSource',\n",
    "\n",
    "        'User Suspicion' :'UserSuspicion',\n",
    "\n",
    "        'Sample Form' :'SampleForm',\n",
    "\n",
    "        'Has the Service User or a close friend tried this batch?' : 'AlreadyTried',\n",
    "\n",
    "        'Your initials' : 'Tester',\n",
    "        'Your name and first initial' : 'Tester',\n",
    "        'Your name and surname initial' : 'Tester'\n",
    "    }\n",
    "    df.rename(columns=d, inplace=True)\n",
    "    \n",
    "    def fix_timestamp(x):\n",
    "        \"\"\"Horror to fix mixed date formats\"\"\"\n",
    "        return pd.to_datetime(str(x), format='%d/%m/%Y %H:%M:%S')\n",
    "#         try:\n",
    "#             x = pd.to_datetime(x)\n",
    "#         except:\n",
    "#             try:\n",
    "#                 # '12/08/2018 12:26:15'\n",
    "#                 x = pd.to_datetime(x, format='%d/%m/%Y %H:%M:%S')\n",
    "#             except:\n",
    "#                 #'Thu 9/08 - 12:19'\n",
    "#                 x = pd.to_datetime(x, format='%a %m/%y - %H:%M')\n",
    "#         return x\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df.loc[:, 'Timestamp'] = df['Timestamp'].map(fix_timestamp)\n",
    "    df.loc[:, 'SampleNumber'] = df['SampleNumber'].apply(fix_sample_number)\n",
    "    df.dropna(subset=['SampleNumber'])\n",
    "    #df.sort_values(['Sample Number'], ascending=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_data(service, SPREADSHEET_ID):\n",
    "\n",
    "    CATALOG_RANGE = 'Catalog!A:R'\n",
    "    FTIR_RANGE = 'FTIR!A:X'\n",
    "    REAGENT_RANGE = 'Reagent!A:W'\n",
    "    MLA_RANGE = 'MLA!A:R'\n",
    "    HR_RANGE = 'Interventions!A:BJ'\n",
    "\n",
    "    #service = gsheets_service()\n",
    "\n",
    "    df_catalog = get_df(service, SPREADSHEET_ID, CATALOG_RANGE)\n",
    "    df_catalog = canonicalise_df(df_catalog, source='catalog')\n",
    "    df_ftir = get_df(service, SPREADSHEET_ID, FTIR_RANGE)\n",
    "    df_ftir = canonicalise_df(df_ftir, source='ftir')\n",
    "    df_reagent = get_df(service, SPREADSHEET_ID, REAGENT_RANGE)\n",
    "    df_reagent = canonicalise_df(df_reagent, source='reagent')\n",
    "    df_mla = get_df(service, SPREADSHEET_ID, MLA_RANGE, mla=True)\n",
    "    df_mla = canonicalise_df(df_mla, source='mla')\n",
    "    try:\n",
    "        df_hr = get_df(service, SPREADSHEET_ID, HR_RANGE)\n",
    "    except ValueError:\n",
    "        df_hr = None\n",
    "    if df_hr is not None:\n",
    "        df_hr = canonicalise_df(df_hr, source='hr')\n",
    "\n",
    "    #DataFrames = namedtuple('DataFrames', ['catalog', 'ftir', 'reagent','mla', 'hr'])\n",
    "    return DataFrames(\n",
    "        catalog=df_catalog,\n",
    "        ftir=df_ftir,\n",
    "        reagent=df_reagent,\n",
    "        mla=df_mla,\n",
    "        hr=df_hr)\n",
    "    return\n",
    "\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "BOOMTOWN2018_SPREADSHEET_ID = '1RiA-FwG_954Ger2VPsOSA3JLh-7sEoTYr40eVS0mp24'\n",
    "MADE2018_SPREADSHEET_ID = '1daXdyL6uL8qnMsEsP0RLZE9nDzt6J7Zr1ygQdguvi-E'\n",
    "BOARDMASTERS2018_SPREADSHEET_ID = '1U1lhUWLazDBN-wb2eZM8YV674f46npVfQK3XUVZjPow'\n",
    "SW42018_SPREADSHEET_ID = '1agpMmJ9XukeWXS5_mwrDSKeshUaFtYwOzsPiR1DKsPU'\n",
    "LOSTVILLAGE2018_SPREADSHEET_ID = '1OL0gyXrpZnJ8e7yR7eF6S2OaBYBiPDoVp5xGpdK4wlA'\n",
    "BESTIVAL2018_SPREADSHEET_ID = '184qudGcw4PB0SMtOo0ZBDtckeGaH0RCLUXbA-u3BiHE'\n",
    "YNOT2018_SPREADSHEET_ID = '1D01cj-Mra06TuoG_MsKuLq9OdtvKzrvRdiE255po_ag'\n",
    "TRUCKFEST2018_SPREADSHEET_ID = '1sGG9WJxKyD2CGUjzJAXul3g9hVnRz6HbTiqKV5cUAyA'\n",
    "LSTD2018_SPREADSHEET_ID = '1R8YqDnrhvuVMwPFShwaaAUIyCXQMeozA230OXsFsDQM'\n",
    "KENDALCALLING2018_SPREADSHEET_ID = '16-PfwBOaUxwod3X75LGk1VAjBblkNsTJpCsX825aghI'\n",
    "PARKLIFE2018_SPREADSHEET_ID = '1oO5sHcUhUn_7M1Hap73sOZHNEfWFMcDkQuWDRFf4d-w'\n",
    "\n",
    "\n",
    "data = {}\n",
    "service = gsheets_service()\n",
    "print \"PROCESSING BOOMTOWN\"\n",
    "data['boomtown'] = get_data(service, BOOMTOWN2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING BOARDMASTERS\"\n",
    "# data['boardmasters'] = get_data(service, BOARDMASTERS2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING MADE\"\n",
    "# data['made'] = get_data(service, MADE2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING SW4\"\n",
    "# data['sw4'] = get_data(service, SW42018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING LOST VILLAGE\"\n",
    "# data['lostvillage'] = get_data(service, LOSTVILLAGE2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING BESTIVAL\"\n",
    "# data['bestival'] = get_data(service, BESTIVAL2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING YNOT\"\n",
    "# data['ynot'] = get_data(service, YNOT2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING TRUCKFEST\"\n",
    "# data['truckfest'] = get_data(service, TRUCKFEST2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING LSTD\"\n",
    "# data['lstd'] = get_data(service, LSTD2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING KENDAL CALLING\"\n",
    "# data['kc'] = get_data(service, KENDALCALLING2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING PARKLIFE\"\n",
    "# data['parklife'] = get_data(service, PARKLIFE2018_SPREADSHEET_ID)\n",
    "\n",
    "import pickle\n",
    "with open('foo_multi.pkl','w') as w:\n",
    "    pickle.dump(data, w)\n",
    "    \n",
    "dfs = data['boomtown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 47 duplicated catalog SampleNumbers ['F0109', 'F0076', 'F0024', 'F0158', 'F0159', 'F0255', 'F0275', 'F0344', 'F0373', 'F0446', 'F0690', 'F0579', 'F0833', 'F0739', 'F0939', 'F0870', 'F0934', 'F0930', 'F0873', 'F0857', 'F0945', 'F0858', 'F0853', 'F0943', 'F0944', 'F0855', 'F0848', 'F0695', 'F0862', 'F0831', 'F0852', 'F0889', 'F0846', 'F0904', 'F0922', 'F1122', 'F0976', 'F1170', 'F0012', 'F1207', 'F1227', 'F1210', 'F1585', 'F1665', 'F1660', 'F1856', 'F1873'] ###\n",
      "### 48 duplicated FTIR SampleNumbers ###\n",
      "### 7 duplicated catalog SampleNumbers ###\n",
      "### 59 duplicated HR SampleNumbers ###\n",
      "Please fix duplicated values\n"
     ]
    }
   ],
   "source": [
    "with open('foo_multi.pkl') as f:\n",
    "    data = pickle.load(f)\n",
    "dfs = data['boomtown']\n",
    "\n",
    "# Check for duplicates\n",
    "catalog_duplicates = dfs.catalog['SampleNumber'].duplicated()\n",
    "if catalog_duplicates.any():\n",
    "    catalog_duplicates = list(dfs.catalog.loc[catalog_duplicates, 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated catalog SampleNumbers %s ###\" % (len(catalog_duplicates), catalog_duplicates))\n",
    "    dfs.catalog[dfs.catalog['SampleNumber'].duplicated(keep=False)].to_csv('catalog_duplicates.csv')\n",
    "else:\n",
    "    catalog_duplicates = None\n",
    "    \n",
    "ftir_duplicates = dfs.ftir['SampleNumber'].duplicated()\n",
    "if ftir_duplicates.any():\n",
    "    ftir_duplicates = list(dfs.ftir.loc[dfs.ftir['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated FTIR SampleNumbers ###\" % len(ftir_duplicates))\n",
    "    dfs.ftir[dfs.ftir['SampleNumber'].duplicated(keep=False)].to_csv('ftir_duplicates.csv')\n",
    "else:\n",
    "    ftir_duplicates = None\n",
    "\n",
    "reagent_duplicates = dfs.reagent['SampleNumber'].duplicated()\n",
    "if reagent_duplicates.any():\n",
    "    reagent_duplicates = list(dfs.reagent.loc[dfs.reagent['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated catalog SampleNumbers ###\" % len(reagent_duplicates))    \n",
    "    dfs.reagent[dfs.reagent['SampleNumber'].duplicated(keep=False)].to_csv('reagent_duplicates.csv', encoding = 'utf-8')\n",
    "else:\n",
    "    reagent_duplicates = None\n",
    "\n",
    "hr_duplicates = None\n",
    "if dfs.hr is not None:\n",
    "    hr_duplicates = dfs.hr['SampleNumber'].duplicated()\n",
    "    if hr_duplicates.any():\n",
    "        hr_duplicates = list(dfs.hr.loc[dfs.hr['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "        print(\"### %d duplicated HR SampleNumbers ###\" % len(hr_duplicates))\n",
    "        dfs.hr[dfs.hr['SampleNumber'].duplicated(keep=False)].to_csv('hr_duplicates.csv', encoding = 'utf-8')\n",
    "    else:\n",
    "        hr_duplicates = None\n",
    "\n",
    "mla_duplicates = dfs.mla['SampleNumber'].duplicated()\n",
    "if mla_duplicates.any():\n",
    "    mla_duplicates = list(dfs.mla.loc[dfs.mla['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated MLA SampleNumbers ###\" % len(mla_duplicates))\n",
    "    dfs.mla[dfs.mla['SampleNumber'].duplicated(keep=False)].to_csv('mla_duplicates.csv')\n",
    "else:\n",
    "    mla_duplicates = None\n",
    "    \n",
    "if catalog_duplicates or \\\n",
    "    ftir_duplicates or \\\n",
    "    reagent_duplicates or \\\n",
    "    hr_duplicates or \\\n",
    "    mla_duplicates:\n",
    "    outs = 'Please fix duplicated values'\n",
    "    print(outs)\n",
    "#     raise RuntimeError(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphaned FTIR sample numbers: ['A1439', 'A1904', 'A1910', 'B0076', 'F00129', 'F0054', 'F0057', 'F0156', 'F0225', 'F0272', 'F0285', 'F0343', 'F0378', 'F0571', 'F0795', 'F0876', 'F0883', 'F0967', 'F0983', 'F1179', 'F1197', 'F1201', 'F1277', 'F1413', 'F1518', 'F1878', 'F1880', 'Z1000']\n",
      "Orphaned Reagent Test sample numbers: ['F0225', 'F0526', 'F0983', 'F1437', 'F1819 (or 1827?)', 'Yellow > green', 'Z1000']\n",
      "Orphaned HR sample numbers: ['F0054', 'F0154', 'F0156', 'F0225', 'F0272', 'F0285', 'F0378', 'F0612', 'F0616', 'F0795', 'F0876', 'F0883', 'F0967', 'F1076', 'F1179', 'F1201', 'F1880', 'F2901', 'F9999', 'G0024', 'G0037', 'G0153', 'G0242', 'G0420', 'G0652', 'G0811', 'G0875', 'G0877', 'G0878', 'G0981', 'G0983', 'G1216', 'G1228', 'G1229', 'G1284', 'G1312', 'G1398', 'G1441', 'G1572', 'G1686', 'G1699', 'G1703', 'G1833', 'G1859', 'G1860', 'G9999']\n",
      "Orphaned MLA sample numbers: ['F0156', 'F0795']\n",
      "Orphaned catalog sample numbers: ['F0516', 'F1012', 'F1104', 'F1168', 'F1243', 'F1488', 'F1910', 'R0876']\n",
      "Samples not in FTIR or Reagent: ['F0368', 'F0369', 'F0871', 'F0879', 'F1582', 'F1746', 'F1819']\n",
      "### Please fix orphaned/catalog only samples ###\n"
     ]
    }
   ],
   "source": [
    "# Check there are no SampleNumbers in any of the other spreadsheets that aren't in the cataolog sheet\n",
    "catalog_unique = set(dfs.catalog['SampleNumber'].unique())\n",
    "\n",
    "ftir_unique = set(dfs.ftir['SampleNumber'].unique())\n",
    "ftir_orphan = ftir_unique.difference(catalog_unique)\n",
    "if ftir_orphan:\n",
    "    print(\"Orphaned FTIR SampleNumbers: %s\" % sorted(ftir_orphan))\n",
    "\n",
    "reagent_unique = set(dfs.reagent['SampleNumber'].unique())\n",
    "reagent_orphan = reagent_unique.difference(catalog_unique)\n",
    "if reagent_orphan:\n",
    "    print(\"Orphaned Reagent Test SampleNumbers: %s\" % sorted(reagent_orphan))\n",
    "\n",
    "hr_unique = set(dfs.hr['SampleNumber'].unique())\n",
    "hr_orphan = hr_unique.difference(catalog_unique)\n",
    "if hr_orphan:\n",
    "    print(\"Orphaned HR SampleNumbers: %s\" % sorted(hr_orphan))\n",
    "    \n",
    "mla_unique = set(dfs.mla['SampleNumber'].unique()).difference(catalog_unique)\n",
    "mla_orphan = mla_unique.difference(catalog_unique)\n",
    "if mla_orphan:\n",
    "    print(\"Orphaned MLA SampleNumbers: %s\" % sorted(mla_orphan))\n",
    "    \n",
    "# Check for any that are only in the catalog\n",
    "outside_catalog = set.union(ftir_unique, reagent_unique, hr_unique, mla_unique)\n",
    "catalog_orphan = catalog_unique.difference(outside_catalog)\n",
    "if catalog_orphan:\n",
    "    print(\"Orphaned catalog SampleNumbers: %s\" % sorted(catalog_orphan))\n",
    "    \n",
    "# Check for any that aren't in FTIR and don't have anything in reagent test\n",
    "ftir_missing = catalog_unique.difference(ftir_unique).difference(reagent_unique).difference(catalog_orphan)\n",
    "if len(ftir_missing):\n",
    "    print(\"Samples not in FTIR or Reagent: %s\" % sorted(ftir_missing))\n",
    "\n",
    "all_unique = copy.copy(ftir_unique)\n",
    "all_unique.update(reagent_unique, hr_unique, mla_unique)\n",
    "if (all_unique or catalog_only):\n",
    "    outs = \"### Please fix orphaned/catalog only samples ###\"\n",
    "    print(outs)\n",
    "    #raise RuntimeError(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    sample_form_d = { 'pill' : ['Ecstasy Tablet',\n",
    "                                'ecstacy pill',\n",
    "                                'Non-pharmaceutical tablet (ecstasy etc)',\n",
    "                                'other recreational pill',\n",
    "                                 'Whole pill',\n",
    "                                'Other pill',\n",
    "                                'Pharmaceutical'],\n",
    "                  'partial pill' : ['Partial ecstasy pill',\n",
    "                                    'Partial 2C-B pill',\n",
    "                                    'Crushed tablet'],\n",
    "                  'powder' : ['Powder/capsule/bomb/crystal',\n",
    "                              'Powder or crushed pill',\n",
    "                              'Crystal, Capsule or Powder'],\n",
    "                  'liquid' : ['*Cannabinoid liquid',\n",
    "                               '*Viscous liquid',\n",
    "                              'Dissolved in Propylene Glycol',\n",
    "                              'Oil'],\n",
    "                   'tab' : ['blotter', 'LSD Tab']\n",
    "                      }\n",
    "\n",
    "\n",
    "    # Firstly convert all columns to lower case and remove any spaces\n",
    "    def lower(value):\n",
    "        if type(value) in [str, unicode]:\n",
    "            value = value.strip().lower()\n",
    "        return value\n",
    "\n",
    "    for column in ['SampleForm']:\n",
    "        df[column] = df[column].map(lower, na_action='ignore')\n",
    "    \n",
    "    replace_d = {}\n",
    "    for column in ['SampleForm']:\n",
    "        replace_d[column] = {}\n",
    "        for drug, names in sample_form_d.items():\n",
    "            for name in names:\n",
    "                replace_d[column][name.lower()] = drug\n",
    "    \n",
    "    # Replace values\n",
    "    df.replace(replace_d, inplace=True)\n",
    "    \n",
    "clean_df(dfs.catalog)\n",
    "clean_df(dfs.ftir)\n",
    "clean_df(dfs.reagent)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First sort out duplicates.\n",
    "For each duplicate sample number:\n",
    "   check if it matches the data in FTIR (and hr?):\n",
    "       if so add the index of the duplicate to the tracker\n",
    "\n",
    "For each duplicate sample number:\n",
    "   if none of the duplicate trackers is True:\n",
    "       mnaually check if we can identify the correct one.\n",
    "\n",
    "For each bad duplicate:\n",
    "    see if any of the orphans in the ftir can be assigned to this duplicate:\n",
    "         if so register the orphan found\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0012 Catalog duplicate sample 1 matches ftir sample 1\n",
      "F0012 Catalog duplicate sample 2 DIFFERENT ftir sample 1\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 20:14:33\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-09 13:44:45\n",
      "F0024 Catalog duplicate sample 3 DIFFERENT ftir sample 1\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 12:27:47\n",
      "['powder', u'Cocaine', u'No'] 2018-08-09 14:51:38\n",
      "F0024 Catalog duplicate sample 4 matches ftir sample 1\n",
      "F0076 Catalog duplicate sample 5 DIFFERENT ftir sample 1\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-09 12:45:08\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:33:48\n",
      "F0076 Catalog duplicate sample 6 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 13:08:00\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:33:48\n",
      "F0109 Catalog duplicate sample 7 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 13:06:16\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:36:24\n",
      "F0109 Catalog duplicate sample 8 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 12:54:36\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 13:36:24\n",
      "F0158 Catalog duplicate sample 9 matches ftir sample 1\n",
      "F0158 Catalog duplicate sample 10 matches ftir sample 2\n",
      "F0158 Catalog duplicate sample 10 matches ftir sample 1\n",
      "F0158 Catalog duplicate sample 11 matches ftir sample 2\n",
      "F0159 Catalog duplicate sample 11 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'No'] 2018-08-09 15:40:53\n",
      "['powder', u'Ketamine', u'No'] 2018-08-09 17:02:03\n",
      "F0159 Catalog duplicate sample 12 matches ftir sample 1\n",
      "F0255 Catalog duplicate sample 13 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-09 17:15:46\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-09 18:28:43\n",
      "F0255 Catalog duplicate sample 14 DIFFERENT ftir sample 1\n",
      "['powder', u'Psilocybin', u'No'] 2018-08-09 16:58:05\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-09 18:28:43\n",
      "F0275 Catalog duplicate sample 15 matches ftir sample 1\n",
      "F0275 Catalog duplicate sample 16 DIFFERENT ftir sample 1\n",
      "['powder', u'MDMA', u'No'] 2018-08-09 18:06:42\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-09 19:34:15\n",
      "F0344 Catalog duplicate sample 17 DIFFERENT ftir sample 1\n",
      "['powder', u'Ketamine', u'No'] 2018-08-09 18:26:30\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-09 19:32:10\n",
      "F0344 Catalog duplicate sample 18 matches ftir sample 1\n",
      "F0373 Catalog duplicate sample 19 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-09 18:40:24\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 20:41:52\n",
      "F0373 Catalog duplicate sample 20 DIFFERENT ftir sample 1\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-09 19:16:35\n",
      "['pill', u'MDMA', u'No'] 2018-08-09 20:41:52\n",
      "F0446 Catalog duplicate sample 21 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'N/A', u'No'] 2018-08-10 14:13:59\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 13:25:19\n",
      "F0446 Catalog duplicate sample 22 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill', u'N/A', u'No'] 2018-08-10 14:13:59\n",
      "['pill', u\"didn't answer\", u'No'] 2018-08-10 14:35:20\n",
      "F0446 Catalog duplicate sample 22 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 13:00:44\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 13:25:19\n",
      "F0446 Catalog duplicate sample 23 DIFFERENT ftir sample 2\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 13:00:44\n",
      "['pill', u\"didn't answer\", u'No'] 2018-08-10 14:35:20\n",
      "F0579 Catalog duplicate sample 23 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-10 15:35:52\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 14:19:34\n",
      "F0579 Catalog duplicate sample 24 DIFFERENT ftir sample 1\n",
      "['pill', u'2C-B', u'Yes'] 2018-08-10 13:56:06\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 14:19:34\n",
      "F0690 Catalog duplicate sample 25 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'Yes'] 2018-08-10 15:05:15\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 15:19:07\n",
      "F0690 Catalog duplicate sample 26 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'Yes'] 2018-08-10 15:02:28\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 15:19:07\n",
      "F0695 Catalog duplicate sample 27 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:53:02\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:34:47\n",
      "F0695 Catalog duplicate sample 28 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:21:19\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:34:47\n",
      "F0739 Catalog duplicate sample 29 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'', u'No'] 2018-08-10 16:58:33\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 16:54:49\n",
      "F0739 Catalog duplicate sample 30 matches ftir sample 1\n",
      "F0831 Catalog duplicate sample 31 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:55:12\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:31:43\n",
      "F0831 Catalog duplicate sample 32 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:27:22\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-10 18:31:43\n",
      "F0833 Catalog duplicate sample 33 matches ftir sample 1\n",
      "F0833 Catalog duplicate sample 34 matches ftir sample 2\n",
      "F0833 Catalog duplicate sample 34 DIFFERENT ftir sample 1\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 16:50:14\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 21:53:33\n",
      "F0833 Catalog duplicate sample 35 DIFFERENT ftir sample 2\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 16:50:14\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-10 22:47:41\n",
      "F0846 Catalog duplicate sample 35 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:24:49\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:26:23\n",
      "F0846 Catalog duplicate sample 36 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:57:34\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:26:23\n",
      "F0848 Catalog duplicate sample 37 matches ftir sample 1\n",
      "F0848 Catalog duplicate sample 38 matches ftir sample 1\n",
      "F0852 Catalog duplicate sample 39 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-10 17:26:32\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 19:29:11\n",
      "F0852 Catalog duplicate sample 40 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-10 17:56:11\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 19:29:11\n",
      "F0853 Catalog duplicate sample 41 matches ftir sample 1\n",
      "F0853 Catalog duplicate sample 42 matches ftir sample 1\n",
      "F0855 Catalog duplicate sample 43 DIFFERENT ftir sample 1\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 17:33:52\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:43:50\n",
      "F0855 Catalog duplicate sample 44 DIFFERENT ftir sample 1\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-10 17:50:11\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:43:50\n",
      "F0857 Catalog duplicate sample 45 matches ftir sample 1\n",
      "F0857 Catalog duplicate sample 46 matches ftir sample 1\n",
      "F0858 Catalog duplicate sample 47 matches ftir sample 1\n",
      "F0858 Catalog duplicate sample 48 matches ftir sample 1\n",
      "F0862 Catalog duplicate sample 49 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:54:22\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:20:02\n",
      "F0862 Catalog duplicate sample 50 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 17:32:23\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:20:02\n",
      "F0870 Catalog duplicate sample 51 matches ftir sample 1\n",
      "F0870 Catalog duplicate sample 52 matches ftir sample 1\n",
      "F0873 Catalog duplicate sample 53 matches ftir sample 1\n",
      "F0873 Catalog duplicate sample 54 matches ftir sample 1\n",
      "F0889 Catalog duplicate sample 55 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:25:41\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:31:59\n",
      "F0889 Catalog duplicate sample 56 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:56:47\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 19:31:59\n",
      "F0904 Catalog duplicate sample 57 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:23:57\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 21:19:05\n",
      "F0904 Catalog duplicate sample 58 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:58:19\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 21:19:05\n",
      "F0922 Catalog duplicate sample 59 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:23:10\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:29:28\n",
      "F0922 Catalog duplicate sample 60 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'No'] 2018-08-10 17:59:17\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:29:28\n",
      "F0934 Catalog duplicate sample 63 matches ftir sample 1\n",
      "F0934 Catalog duplicate sample 64 matches ftir sample 1\n",
      "F0939 Catalog duplicate sample 65 matches ftir sample 1\n",
      "F0939 Catalog duplicate sample 66 matches ftir sample 1\n",
      "F0943 Catalog duplicate sample 67 matches ftir sample 1\n",
      "F0943 Catalog duplicate sample 68 matches ftir sample 1\n",
      "F0944 Catalog duplicate sample 69 matches ftir sample 1\n",
      "F0944 Catalog duplicate sample 70 matches ftir sample 1\n",
      "F0945 Catalog duplicate sample 71 matches ftir sample 1\n",
      "F0945 Catalog duplicate sample 72 matches ftir sample 1\n",
      "F0976 Catalog duplicate sample 73 DIFFERENT ftir sample 1\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 18:27:12\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 21:00:43\n",
      "F0976 Catalog duplicate sample 74 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'Yes'] 2018-08-10 18:55:30\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-10 21:00:43\n",
      "F1122 Catalog duplicate sample 75 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'No'] 2018-08-10 18:52:45\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:12:19\n",
      "F1122 Catalog duplicate sample 76 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill', u'MDMA', u'No'] 2018-08-10 18:52:45\n",
      "['powder', u'Ketamine', u'No'] 2018-08-11 11:14:50\n",
      "F1122 Catalog duplicate sample 76 DIFFERENT ftir sample 1\n",
      "['powder', u'Ketamine', u'No'] 2018-08-10 18:30:17\n",
      "['pill', u'MDMA', u'No'] 2018-08-10 22:12:19\n",
      "F1122 Catalog duplicate sample 77 matches ftir sample 2\n",
      "F1170 Catalog duplicate sample 77 DIFFERENT ftir sample 1\n",
      "['partial pill', u'Found or otherwise not known', u'No'] 2018-08-10 19:19:39\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-10 21:42:11\n",
      "F1170 Catalog duplicate sample 78 matches ftir sample 1\n",
      "F1207 Catalog duplicate sample 79 matches ftir sample 1\n",
      "F1207 Catalog duplicate sample 80 DIFFERENT ftir sample 1\n",
      "['partial pill', u'MDMA', u'Yes'] 2018-08-11 13:54:36\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 13:56:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1210 Catalog duplicate sample 81 matches ftir sample 1\n",
      "F1210 Catalog duplicate sample 82 DIFFERENT ftir sample 2\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-11 14:07:22\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 14:13:21\n",
      "F1210 Catalog duplicate sample 82 DIFFERENT ftir sample 1\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 14:06:48\n",
      "['powder', u'Ketamine', u'Yes'] 2018-08-11 14:11:54\n",
      "F1210 Catalog duplicate sample 83 matches ftir sample 2\n",
      "F1227 Catalog duplicate sample 83 matches ftir sample 1\n",
      "F1227 Catalog duplicate sample 84 DIFFERENT ftir sample 1\n",
      "['powder', u'Found or otherwise not known', u'Yes'] 2018-08-11 13:02:59\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-11 14:21:37\n",
      "F1585 Catalog duplicate sample 85 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'Yes'] 2018-08-11 15:02:54\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-11 15:41:13\n",
      "F1585 Catalog duplicate sample 86 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'Yes'] 2018-08-11 15:06:13\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-11 15:41:13\n",
      "F1660 Catalog duplicate sample 87 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'Found or otherwise not known', u'No'] 2018-08-11 17:45:35\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-11 17:49:56\n",
      "F1660 Catalog duplicate sample 88 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill', u'Found or otherwise not known', u'No'] 2018-08-11 17:45:35\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-12 12:07:18\n",
      "F1660 Catalog duplicate sample 88 DIFFERENT ftir sample 1\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-11 17:48:30\n",
      "['pill', u'Found or otherwise not known', u'No'] 2018-08-11 17:49:56\n",
      "F1660 Catalog duplicate sample 89 matches ftir sample 2\n",
      "F1665 Catalog duplicate sample 89 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'No'] 2018-08-11 17:48:06\n",
      "['pill', u'MDMA', u'No'] 2018-08-11 17:51:56\n",
      "F1665 Catalog duplicate sample 90 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill', u'MDMA', u'No'] 2018-08-11 17:48:06\n",
      "['powder', u'MDMA', u'No'] 2018-08-11 19:11:15\n",
      "F1665 Catalog duplicate sample 90 DIFFERENT ftir sample 1\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-11 17:44:25\n",
      "['pill', u'MDMA', u'No'] 2018-08-11 17:51:56\n",
      "F1665 Catalog duplicate sample 91 DIFFERENT ftir sample 2\n",
      "['powder', u'Found or otherwise not known', u'No'] 2018-08-11 17:44:25\n",
      "['powder', u'MDMA', u'No'] 2018-08-11 19:11:15\n",
      "F1856 Catalog duplicate sample 91 matches ftir sample 1\n",
      "F1856 Catalog duplicate sample 92 matches ftir sample 1\n",
      "F1873 Catalog duplicate sample 93 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill', u'MDMA', u'Yes'] 2018-08-12 16:01:30\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-12 16:16:23\n",
      "F1873 Catalog duplicate sample 94 DIFFERENT ftir sample 1\n",
      "['powder', u'MDMA', u'Yes'] 2018-08-12 15:28:04\n",
      "['pill', u'MDMA', u'Yes'] 2018-08-12 16:16:23\n"
     ]
    }
   ],
   "source": [
    "# print(dir(dfs.catalog.loc[dfs.catalog['Sample Number'].isin(catalog_duplicates)]))\n",
    "duplicates = []\n",
    "for sample_number in catalog_duplicates:\n",
    "    for i, cat_row in enumerate(dfs.catalog.loc[dfs.catalog['SampleNumber'] == sample_number].itertuples())):\n",
    "        for j, ftir_row in enumerate(dfs.ftir.loc[dfs.ftir['SampleNumber'] == sample_number].itertuples()):\n",
    "            i += 1\n",
    "            j += 1\n",
    "            catalog_data = [cat_row.SampleForm, cat_row.SoldAs, cat_row.AlreadyTried]\n",
    "            catalog_time = cat_row.Timestamp\n",
    "            ftir_data = [ftir_row.SampleForm, ftir_row.SoldAs, ftir_row.AlreadyTried]\n",
    "            ftir_time = ftir_row.Timestamp\n",
    "            if catalog_data == ftir_data and ftir_time > catalog_time:\n",
    "                print(\"%s Catalog duplicate sample %d matches ftir sample %d\" % (sample_number, i, j))\n",
    "            else:\n",
    "                print(\"%s Catalog duplicate sample %d DIFFERENT ftir sample %d\\n%s %s\\n%s %s\" % (sample_number, i, j,\n",
    "                                                                                              catalog_data, catalog_time,\n",
    "                                                                                              ftir_data, ftir_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0024 Catalog duplicate sample 1 DIFFERENT ftir sample 1\n",
      "['powder' u'MDMA' u'No'] 2018-08-09 12:27:47\n",
      "['powder' u'Cocaine' u'No'] 2018-08-09 14:51:38\n",
      "F0076 Catalog duplicate sample 2 DIFFERENT ftir sample 1\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-09 12:45:08\n",
      "['pill' u'MDMA' u'No'] 2018-08-09 13:33:48\n",
      "F0109 Catalog duplicate sample 3 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-09 12:54:36\n",
      "['pill' u'MDMA' u'No'] 2018-08-09 13:36:24\n",
      "F0012 Catalog duplicate sample 4 matches ftir sample 1\n",
      "F0109 Catalog duplicate sample 5 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-09 13:06:16\n",
      "['pill' u'MDMA' u'No'] 2018-08-09 13:36:24\n",
      "F0076 Catalog duplicate sample 6 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-09 13:08:00\n",
      "['pill' u'MDMA' u'No'] 2018-08-09 13:33:48\n",
      "F0024 Catalog duplicate sample 7 matches ftir sample 1\n",
      "F0159 Catalog duplicate sample 8 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'No'] 2018-08-09 15:40:53\n",
      "['powder' u'Ketamine' u'No'] 2018-08-09 17:02:03\n",
      "F0158 Catalog duplicate sample 9 matches ftir sample 1\n",
      "F0158 Catalog duplicate sample 10 matches ftir sample 2\n",
      "F0158 Catalog duplicate sample 10 matches ftir sample 1\n",
      "F0158 Catalog duplicate sample 11 matches ftir sample 2\n",
      "F0159 Catalog duplicate sample 11 matches ftir sample 1\n",
      "F0255 Catalog duplicate sample 12 DIFFERENT ftir sample 1\n",
      "['powder' u'Psilocybin' u'No'] 2018-08-09 16:58:05\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-09 18:28:43\n",
      "F0255 Catalog duplicate sample 13 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-09 17:15:46\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-09 18:28:43\n",
      "F0275 Catalog duplicate sample 14 matches ftir sample 1\n",
      "F0344 Catalog duplicate sample 15 matches ftir sample 1\n",
      "F0275 Catalog duplicate sample 16 DIFFERENT ftir sample 1\n",
      "['powder' u'MDMA' u'No'] 2018-08-09 18:06:42\n",
      "['powder' u'Cocaine' u'Yes'] 2018-08-09 19:34:15\n",
      "F0344 Catalog duplicate sample 17 DIFFERENT ftir sample 1\n",
      "['powder' u'Ketamine' u'No'] 2018-08-09 18:26:30\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-09 19:32:10\n",
      "F0373 Catalog duplicate sample 18 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-09 18:40:24\n",
      "['pill' u'MDMA' u'No'] 2018-08-09 20:41:52\n",
      "F0373 Catalog duplicate sample 19 DIFFERENT ftir sample 1\n",
      "['powder' u'Cocaine' u'Yes'] 2018-08-09 19:16:35\n",
      "['pill' u'MDMA' u'No'] 2018-08-09 20:41:52\n",
      "F0446 Catalog duplicate sample 20 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 13:00:44\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 13:25:19\n",
      "F0446 Catalog duplicate sample 21 DIFFERENT ftir sample 2\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 13:00:44\n",
      "['pill' u\"didn't answer\" u'No'] 2018-08-10 14:35:20\n",
      "F0579 Catalog duplicate sample 21 DIFFERENT ftir sample 1\n",
      "['pill' u'2C-B' u'Yes'] 2018-08-10 13:56:06\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 14:19:34\n",
      "F0446 Catalog duplicate sample 22 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'N/A' u'No'] 2018-08-10 14:13:59\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 13:25:19\n",
      "F0446 Catalog duplicate sample 23 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill' u'N/A' u'No'] 2018-08-10 14:13:59\n",
      "['pill' u\"didn't answer\" u'No'] 2018-08-10 14:35:20\n",
      "F0690 Catalog duplicate sample 23 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'Yes'] 2018-08-10 15:02:28\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 15:19:07\n",
      "F0690 Catalog duplicate sample 24 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'Yes'] 2018-08-10 15:05:15\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 15:19:07\n",
      "F0579 Catalog duplicate sample 25 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'Yes'] 2018-08-10 15:35:52\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 14:19:34\n",
      "F0739 Catalog duplicate sample 26 matches ftir sample 1\n",
      "F0833 Catalog duplicate sample 27 matches ftir sample 1\n",
      "F0833 Catalog duplicate sample 28 matches ftir sample 2\n",
      "F0833 Catalog duplicate sample 28 DIFFERENT ftir sample 1\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-10 16:50:14\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-10 21:53:33\n",
      "F0833 Catalog duplicate sample 29 DIFFERENT ftir sample 2\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-10 16:50:14\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-10 22:47:41\n",
      "F0739 Catalog duplicate sample 29 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'' u'No'] 2018-08-10 16:58:33\n",
      "['powder' u'Cocaine' u'Yes'] 2018-08-10 16:54:49\n",
      "F0695 Catalog duplicate sample 30 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 17:21:19\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-10 18:34:47\n",
      "F0922 Catalog duplicate sample 31 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:23:10\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 18:29:28\n",
      "F0904 Catalog duplicate sample 32 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:23:57\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 21:19:05\n",
      "F0846 Catalog duplicate sample 33 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:24:49\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 22:26:23\n",
      "F0889 Catalog duplicate sample 34 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:25:41\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 19:31:59\n",
      "F0852 Catalog duplicate sample 35 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'Yes'] 2018-08-10 17:26:32\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 19:29:11\n",
      "F0831 Catalog duplicate sample 36 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 17:27:22\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-10 18:31:43\n",
      "F0862 Catalog duplicate sample 37 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 17:32:23\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 19:20:02\n",
      "F0848 Catalog duplicate sample 38 matches ftir sample 1\n",
      "F0855 Catalog duplicate sample 39 DIFFERENT ftir sample 1\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-10 17:33:52\n",
      "['powder' u'Ketamine' u'No'] 2018-08-10 18:43:50\n",
      "F0944 Catalog duplicate sample 40 matches ftir sample 1\n",
      "F0943 Catalog duplicate sample 41 matches ftir sample 1\n",
      "F0853 Catalog duplicate sample 42 matches ftir sample 1\n",
      "F0858 Catalog duplicate sample 43 matches ftir sample 1\n",
      "F0945 Catalog duplicate sample 44 matches ftir sample 1\n",
      "F0857 Catalog duplicate sample 45 matches ftir sample 1\n",
      "F0873 Catalog duplicate sample 46 matches ftir sample 1\n",
      "F0934 Catalog duplicate sample 47 matches ftir sample 1\n",
      "F0870 Catalog duplicate sample 48 matches ftir sample 1\n",
      "F0939 Catalog duplicate sample 49 matches ftir sample 1\n",
      "F0939 Catalog duplicate sample 51 matches ftir sample 1\n",
      "F0870 Catalog duplicate sample 52 matches ftir sample 1\n",
      "F0934 Catalog duplicate sample 53 matches ftir sample 1\n",
      "F0873 Catalog duplicate sample 55 matches ftir sample 1\n",
      "F0857 Catalog duplicate sample 56 matches ftir sample 1\n",
      "F0945 Catalog duplicate sample 57 matches ftir sample 1\n",
      "F0858 Catalog duplicate sample 58 matches ftir sample 1\n",
      "F0853 Catalog duplicate sample 59 matches ftir sample 1\n",
      "F0943 Catalog duplicate sample 60 matches ftir sample 1\n",
      "F0944 Catalog duplicate sample 61 matches ftir sample 1\n",
      "F0855 Catalog duplicate sample 62 DIFFERENT ftir sample 1\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-10 17:50:11\n",
      "['powder' u'Ketamine' u'No'] 2018-08-10 18:43:50\n",
      "F0848 Catalog duplicate sample 63 matches ftir sample 1\n",
      "F0695 Catalog duplicate sample 64 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 17:53:02\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-10 18:34:47\n",
      "F0862 Catalog duplicate sample 65 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 17:54:22\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 19:20:02\n",
      "F0831 Catalog duplicate sample 66 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 17:55:12\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-10 18:31:43\n",
      "F0852 Catalog duplicate sample 67 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'Yes'] 2018-08-10 17:56:11\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 19:29:11\n",
      "F0889 Catalog duplicate sample 68 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:56:47\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 19:31:59\n",
      "F0846 Catalog duplicate sample 69 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:57:34\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 22:26:23\n",
      "F0904 Catalog duplicate sample 70 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:58:19\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 21:19:05\n",
      "F0922 Catalog duplicate sample 71 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'No'] 2018-08-10 17:59:17\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 18:29:28\n",
      "F0976 Catalog duplicate sample 72 DIFFERENT ftir sample 1\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 18:27:12\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 21:00:43\n",
      "F1122 Catalog duplicate sample 73 DIFFERENT ftir sample 1\n",
      "['powder' u'Ketamine' u'No'] 2018-08-10 18:30:17\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 22:12:19\n",
      "F1122 Catalog duplicate sample 74 matches ftir sample 2\n",
      "F1122 Catalog duplicate sample 74 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'No'] 2018-08-10 18:52:45\n",
      "['pill' u'MDMA' u'No'] 2018-08-10 22:12:19\n",
      "F1122 Catalog duplicate sample 75 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill' u'MDMA' u'No'] 2018-08-10 18:52:45\n",
      "['powder' u'Ketamine' u'No'] 2018-08-11 11:14:50\n",
      "F0976 Catalog duplicate sample 75 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'Yes'] 2018-08-10 18:55:30\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-10 21:00:43\n",
      "F1170 Catalog duplicate sample 76 DIFFERENT ftir sample 1\n",
      "['partial pill' u'Found or otherwise not known' u'No'] 2018-08-10 19:19:39\n",
      "['powder' u'Cocaine' u'Yes'] 2018-08-10 21:42:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1170 Catalog duplicate sample 77 matches ftir sample 1\n",
      "F0012 Catalog duplicate sample 78 DIFFERENT ftir sample 1\n",
      "['powder' u'Cocaine' u'Yes'] 2018-08-10 20:14:33\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-09 13:44:45\n",
      "F1227 Catalog duplicate sample 79 DIFFERENT ftir sample 1\n",
      "['powder' u'Found or otherwise not known' u'Yes'] 2018-08-11 13:02:59\n",
      "['powder' u'Cocaine' u'Yes'] 2018-08-11 14:21:37\n",
      "F1207 Catalog duplicate sample 80 matches ftir sample 1\n",
      "F1207 Catalog duplicate sample 81 DIFFERENT ftir sample 1\n",
      "['partial pill' u'MDMA' u'Yes'] 2018-08-11 13:54:36\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-11 13:56:33\n",
      "F1227 Catalog duplicate sample 82 matches ftir sample 1\n",
      "F1210 Catalog duplicate sample 83 DIFFERENT ftir sample 1\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-11 14:06:48\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-11 14:11:54\n",
      "F1210 Catalog duplicate sample 84 matches ftir sample 2\n",
      "F1210 Catalog duplicate sample 84 matches ftir sample 1\n",
      "F1210 Catalog duplicate sample 85 DIFFERENT ftir sample 2\n",
      "['powder' u'Ketamine' u'Yes'] 2018-08-11 14:07:22\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-11 14:13:21\n",
      "F1585 Catalog duplicate sample 85 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'Yes'] 2018-08-11 15:02:54\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-11 15:41:13\n",
      "F1585 Catalog duplicate sample 86 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'Yes'] 2018-08-11 15:06:13\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-11 15:41:13\n",
      "F1665 Catalog duplicate sample 87 DIFFERENT ftir sample 1\n",
      "['powder' u'Found or otherwise not known' u'No'] 2018-08-11 17:44:25\n",
      "['pill' u'MDMA' u'No'] 2018-08-11 17:51:56\n",
      "F1665 Catalog duplicate sample 88 DIFFERENT ftir sample 2\n",
      "['powder' u'Found or otherwise not known' u'No'] 2018-08-11 17:44:25\n",
      "['powder' u'MDMA' u'No'] 2018-08-11 19:11:15\n",
      "F1660 Catalog duplicate sample 88 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'Found or otherwise not known' u'No'] 2018-08-11 17:45:35\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-11 17:49:56\n",
      "F1660 Catalog duplicate sample 89 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill' u'Found or otherwise not known' u'No'] 2018-08-11 17:45:35\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-12 12:07:18\n",
      "F1665 Catalog duplicate sample 89 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'No'] 2018-08-11 17:48:06\n",
      "['pill' u'MDMA' u'No'] 2018-08-11 17:51:56\n",
      "F1665 Catalog duplicate sample 90 DIFFERENT ftir sample 2\n",
      "[u'ecstasy pill' u'MDMA' u'No'] 2018-08-11 17:48:06\n",
      "['powder' u'MDMA' u'No'] 2018-08-11 19:11:15\n",
      "F1660 Catalog duplicate sample 90 DIFFERENT ftir sample 1\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-11 17:48:30\n",
      "['pill' u'Found or otherwise not known' u'No'] 2018-08-11 17:49:56\n",
      "F1660 Catalog duplicate sample 91 matches ftir sample 2\n",
      "F1856 Catalog duplicate sample 91 matches ftir sample 1\n",
      "F1856 Catalog duplicate sample 92 matches ftir sample 1\n",
      "F1873 Catalog duplicate sample 93 DIFFERENT ftir sample 1\n",
      "['powder' u'MDMA' u'Yes'] 2018-08-12 15:28:04\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-12 16:16:23\n",
      "F1873 Catalog duplicate sample 94 DIFFERENT ftir sample 1\n",
      "[u'ecstasy pill' u'MDMA' u'Yes'] 2018-08-12 16:01:30\n",
      "['pill' u'MDMA' u'Yes'] 2018-08-12 16:16:23\n"
     ]
    }
   ],
   "source": [
    "# print(dir(dfs.catalog.loc[dfs.catalog['Sample Number'].isin(catalog_duplicates)]))\n",
    "duplicates = []\n",
    "for i, (cat_idx, cat_row) in enumerate(dfs.catalog.loc[dfs.catalog['SampleNumber'].isin(catalog_duplicates)].iterrows()):\n",
    "    sample_number = cat_row.at['SampleNumber']\n",
    "    for j, (ftir_idx, ftir_row) in enumerate(dfs.ftir.loc[dfs.ftir['SampleNumber'] == cat_row['SampleNumber']].iterrows()):\n",
    "        i += 1\n",
    "        j += 1\n",
    "        catalog_data = cat_row.loc[['SampleForm', 'SoldAs', 'AlreadyTried']].values\n",
    "        catalog_time = cat_row.at['Timestamp']\n",
    "        ftir_data = ftir_row.loc[['Sample Form', 'SoldAs', 'AlreadyTried']].values\n",
    "        ftir_time = ftir_row.at['Timestamp']       \n",
    "        if np.all(catalog_data == ftir_data) and ftir_time > catalog_time:\n",
    "            print(\"%s Catalog duplicate sample %d matches ftir sample %d\" % (sample_number, i, j))\n",
    "        else:\n",
    "            print(\"%s Catalog duplicate sample %d DIFFERENT ftir sample %d\\n%s %s\\n%s %s\" % (sample_number, i, j,\n",
    "                                                                                          catalog_data, catalog_time,\n",
    "                                                                                          ftir_data, ftir_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c_sn in sorted(list(catalog_orphan)):\n",
    "    for f_cn in sorted(list(ftir_orphan)):\n",
    "        print(\"CHECKING \",c_sn, f_sn)\n",
    "        c = dfs.catalog.loc[dfs.catalog['Sample Number'] == c_sn, ['Sold As', 'Sample Form', 'Already Tried', 'User Suspicion']]\n",
    "        ct = dfs.catalog.loc[dfs.catalog['Sample Number'] == c_sn, ['Timestamp']].iat[0,0]\n",
    "        f = dfs.ftir.loc[dfs.ftir['Sample Number'] == f_sn, ['Sold As', 'Sample Form', 'Already Tried', 'User Suspicion']]\n",
    "        ft = dfs.ftir.loc[dfs.ftir['Sample Number'] == f_sn, ['Timestamp']].iat[0,0]\n",
    "        print(\"%s - %s\" % (c.values == f.values, ft > ct))\n",
    "        if np.all(c.values == f.values) and ft > ct:\n",
    "            print(\"Catalog %s matches FTIR %s\" % c_sn, f_sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up catalog\n",
    "# Drop all unwanted columns\n",
    "\n",
    "#  or 'Your initials'\n",
    "l = set(['Your initials',\n",
    "         'Your name and first initial',\n",
    "         'Which device was a photo taken with? Who does it belong to?',\n",
    "         'Is a breakline present?',\n",
    "         'Unusual appearance'\n",
    "        ])\n",
    "\n",
    "to_drop = set(dfs.catalog.columns).intersection(l)\n",
    "dfs.catalog.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "d = {\n",
    "    'Timestamp' : 'Catalog timestamp',\n",
    "    'Sample Advertised/Acquired/Sold As': 'Catalog_SoldAs',\n",
    "    'Sample Form' : 'Catalog_Form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'Catalog_Tried',\n",
    "    'What is the mass? (mg)': 'FullPillMass',\n",
    "    'What is the shape of the pill?': 'PillShape',\n",
    "    'What is the logo?': 'PillLogo',\n",
    "    'What colour is the pill?': 'PillColour'\n",
    "}\n",
    "dfs.catalog.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('COLS ', Index([                                                           u'Timestamp',\n",
      "                                                              u'Sample Number',\n",
      "                                                                     u'Tester',\n",
      "                                                                    u'Sold As',\n",
      "                                                                u'Sample Form',\n",
      "                                                              u'Already Tried',\n",
      "                                                             u'User Suspicion',\n",
      "                                                         u'Substance detected',\n",
      "                                                             u'Hit Confidence',\n",
      "                                                          u'Compound detected',\n",
      "                                                           u'Hit Confidence.1',\n",
      "                                                                 u'Brief Note',\n",
      "                           u'Is anything detected after subtraction analysis?',\n",
      "                                            u'Compound detected (Subtraction)',\n",
      "                                                           u'Hit Confidence.2',\n",
      "                                                       u'Substance detected.1',\n",
      "                                                           u'Hit Confidence.3',\n",
      "                                                               u'Brief Note.1',\n",
      "                                                             u'Next action(s)',\n",
      "                                                      u'Substance(s) detected',\n",
      "                                           u'\"Strength\" of powdered substance',\n",
      "       u'Does the substance detected match the substance that was advertised?',\n",
      "                                             u'Note for harm reduction worker',\n",
      "                                                            u'Send to HR team'],\n",
      "      dtype='object'))\n",
      "('SS ', 1691    N-Ethylpentylone\n",
      "1692    N-Ethylpentylone\n",
      "1694    N-Ethylpentylone\n",
      "1696             Cocaine\n",
      "0                   MDMA\n",
      "Name: Substance detected, dtype: object)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_ftir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f76c2c2a13ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_ftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Copy values from 'Compound detected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Brief Note.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ftir' is not defined"
     ]
    }
   ],
   "source": [
    "# For FTIR columns need to merge the data from the 'Compound detected', 'Hit Confidence.1' columns into the\n",
    "# 'Substance detected', 'Hit Confidence' column where the substance detected was 'other'\n",
    "print(\"COLS \",dfs.ftir.columns)\n",
    "print(\"SS \",dfs.ftir['Substance detected'][:5])\n",
    "mask = dfs.ftir['Substance detected'] != 'Other'\n",
    "dfs.ftir['Substance detected'].where(mask, dfs.ftir['Compound detected'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence'].where(mask, dfs.ftir['Hit Confidence.1'], inplace=True)\n",
    "dfs.ftir.drop(['Compound detected', 'Hit Confidence.1', 'Brief Note'], axis=1, inplace=True)\n",
    "\n",
    "mask = dfs.ftir['Compound detected (Subtraction)'] != 'Other'\n",
    "dfs.ftir['Compound detected (Subtraction)'].where(mask, df_ftir['Substance detected.1'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence.2'].where(mask, dfs.ftir['Hit Confidence.3'], inplace=True)\n",
    "dfs.ftir.drop(['Substance detected.1', 'Hit Confidence.3', 'Brief Note.1'], axis=1, inplace=True)\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['Your name and surname initial',\n",
    "     'User Suspicion',\n",
    "     'Is anything detected after subtraction analysis?',\n",
    "     'Analysis required', \n",
    "     'Next action(s)',\n",
    "     'Send to HR team'\n",
    "    ]\n",
    "#'Note for harm reduction worker'\n",
    "to_drop = set(dfs.ftir.columns).intersection(l)\n",
    "dfs.ftir.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'FTIR timestamp',\n",
    "    'Sample Sold As': 'FTIR Sold As',\n",
    "    'Sample Form' : 'FTIR form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'FTIR tried',\n",
    "    'Substance(s) detected' : 'FTIR final result',\n",
    "    'Substance detected' : 'FTIR result1',\n",
    "    'Hit Confidence' :  'FTIR hit1',\n",
    "    'Is anything detected after subtraction analysis?' : 'FTIR subtraction positive',\n",
    "    'Compound detected (Subtraction)' :  'FTIR result2',\n",
    "    'Hit Confidence.2' :  'FTIR hit2',\n",
    "    '\"Strength\" of powdered substance' : 'FTIR Powder Strength',\n",
    "    'Does the substance detected match the substance that was advertised?' : 'FTIR Matches Sold As',\n",
    "}\n",
    "dfs.ftir.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up HR form\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['HR worker name:']\n",
    "dfs.hr.drop(l, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'HR timestamp',\n",
    "    'You submitted a substance for analysis. What were you told it was when you got it?': 'HR Sold as',\n",
    "    'Had you already tried this substance before getting it tested?': 'HR tried',\n",
    "    'What was your first sample number at this event? Did you take a photo or keep the ticket?': 'Previous Sample Number'\n",
    "}\n",
    "dfs.hr.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Catalog and FTIR data frames\n",
    "df_all = pd.merge(dfs.catalog, dfs.ftir, how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in any reagent test data\n",
    "df_all = pd.merge(df_all, dfs.reagent[['Sample Number', 'Reagent Result']], how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in any pill strength data\n",
    "df_all = pd.merge(df_all, dfs.mla[['Sample Number', 'MDMA / tablet (mg)', '% MDMA content']], how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in HR data\n",
    "df_all = pd.merge(df_all, dfs.hr, how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix column orders\n",
    "prefix = ['Sample Number',\n",
    "          'Catalog timestamp', 'FTIR timestamp', 'HR timestamp',\n",
    "          'Catalog Sold As', 'FTIR Sold As','HR Sold as', \n",
    "          'Catalog form', 'FTIR form',\n",
    "          'Catalog tried', 'FTIR tried', 'HR tried']\n",
    "columns = [c for c in df_all.columns if c not in prefix]\n",
    "columns = prefix + columns\n",
    "df_all = df_all[columns]\n",
    "df_all.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
